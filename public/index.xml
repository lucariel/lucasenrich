<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Lucas Enrich</title>
    <link>/</link>
      <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <description>Lucas Enrich</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sat, 01 Jun 2030 13:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Lucas Enrich</title>
      <link>/</link>
    </image>
    
    <item>
      <title>Example Page 1</title>
      <link>/courses/example/example1/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>/courses/example/example1/</guid>
      <description>&lt;p&gt;In this tutorial, I&amp;rsquo;ll share my top 10 tips for getting started with Academic:&lt;/p&gt;
&lt;h2 id=&#34;tip-1&#34;&gt;Tip 1&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
&lt;h2 id=&#34;tip-2&#34;&gt;Tip 2&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Example Page 2</title>
      <link>/courses/example/example2/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>/courses/example/example2/</guid>
      <description>&lt;p&gt;Here are some more tips for getting started with Academic:&lt;/p&gt;
&lt;h2 id=&#34;tip-3&#34;&gt;Tip 3&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
&lt;h2 id=&#34;tip-4&#34;&gt;Tip 4&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Example Talk</title>
      <link>/talk/example/</link>
      <pubDate>Sat, 01 Jun 2030 13:00:00 +0000</pubDate>
      <guid>/talk/example/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Slides can be added in a few ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Create&lt;/strong&gt; slides using Academic&amp;rsquo;s 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Slides&lt;/em&gt;&lt;/a&gt; feature and link using &lt;code&gt;slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt; an existing slide deck to &lt;code&gt;static/&lt;/code&gt; and link using &lt;code&gt;url_slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Embed&lt;/strong&gt; your slides (e.g. Google Slides) or presentation video on this page using 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;shortcodes&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Further talk details can easily be added to this page using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Writing technical content in Academic</title>
      <link>/post/prev/writing-technical-content/</link>
      <pubDate>Fri, 12 Jul 2019 00:00:00 +0000</pubDate>
      <guid>/post/prev/writing-technical-content/</guid>
      <description>&lt;p&gt;Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Highlight your code snippets, take notes on math classes, and draw diagrams from textual representation.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;On this page, you&amp;rsquo;ll find some examples of the types of technical content that can be rendered with Academic.&lt;/p&gt;
&lt;h2 id=&#34;examples&#34;&gt;Examples&lt;/h2&gt;
&lt;h3 id=&#34;code&#34;&gt;Code&lt;/h3&gt;
&lt;p&gt;Academic supports a Markdown extension for highlighting code syntax. You can enable this feature by toggling the &lt;code&gt;highlight&lt;/code&gt; option in your &lt;code&gt;config/_default/params.toml&lt;/code&gt; file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```python
import pandas as pd
data = pd.read_csv(&amp;quot;data.csv&amp;quot;)
data.head()
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pandas as pd
data = pd.read_csv(&amp;quot;data.csv&amp;quot;)
data.head()
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;math&#34;&gt;Math&lt;/h3&gt;
&lt;p&gt;Academic supports a Markdown extension for $\LaTeX$ math. You can enable this feature by toggling the &lt;code&gt;math&lt;/code&gt; option in your &lt;code&gt;config/_default/params.toml&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;To render &lt;em&gt;inline&lt;/em&gt; or &lt;em&gt;block&lt;/em&gt; math, wrap your LaTeX math with &lt;code&gt;$...$&lt;/code&gt; or &lt;code&gt;$$...$$&lt;/code&gt;, respectively.&lt;/p&gt;
&lt;p&gt;Example &lt;strong&gt;math block&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-tex&#34;&gt;$$\gamma_{n} = \frac{ 
\left | \left (\mathbf x_{n} - \mathbf x_{n-1} \right )^T 
\left [\nabla F (\mathbf x_{n}) - \nabla F (\mathbf x_{n-1}) \right ] \right |}
{\left \|\nabla F(\mathbf{x}_{n}) - \nabla F(\mathbf{x}_{n-1}) \right \|^2}$$
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;p&gt;$$\gamma_{n} = \frac{ \left | \left (\mathbf x_{n} - \mathbf x_{n-1} \right )^T \left [\nabla F (\mathbf x_{n}) - \nabla F (\mathbf x_{n-1}) \right ] \right |}{\left |\nabla F(\mathbf{x}_{n}) - \nabla F(\mathbf{x}_{n-1}) \right |^2}$$&lt;/p&gt;
&lt;p&gt;Example &lt;strong&gt;inline math&lt;/strong&gt; &lt;code&gt;$\nabla F(\mathbf{x}_{n})$&lt;/code&gt; renders as $\nabla F(\mathbf{x}_{n})$.&lt;/p&gt;
&lt;p&gt;Example &lt;strong&gt;multi-line math&lt;/strong&gt; using the &lt;code&gt;\\\\&lt;/code&gt; math linebreak:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-tex&#34;&gt;$$f(k;p_0^*) = \begin{cases} p_0^* &amp;amp; \text{if }k=1, \\\\
1-p_0^* &amp;amp; \text {if }k=0.\end{cases}$$
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;p&gt;$$f(k;p_0^*) = \begin{cases} p_0^* &amp;amp; \text{if }k=1, \\&lt;br&gt;
1-p_0^* &amp;amp; \text {if }k=0.\end{cases}$$&lt;/p&gt;
&lt;h3 id=&#34;diagrams&#34;&gt;Diagrams&lt;/h3&gt;
&lt;p&gt;Academic supports a Markdown extension for diagrams. You can enable this feature by toggling the &lt;code&gt;diagram&lt;/code&gt; option in your &lt;code&gt;config/_default/params.toml&lt;/code&gt; file or by adding &lt;code&gt;diagram: true&lt;/code&gt; to your page front matter.&lt;/p&gt;
&lt;p&gt;An example &lt;strong&gt;flowchart&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
graph TD
A[Hard] --&amp;gt;|Text| B(Round)
B --&amp;gt; C{Decision}
C --&amp;gt;|One| D[Result 1]
C --&amp;gt;|Two| E[Result 2]
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph TD
A[Hard] --&amp;gt;|Text| B(Round)
B --&amp;gt; C{Decision}
C --&amp;gt;|One| D[Result 1]
C --&amp;gt;|Two| E[Result 2]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An example &lt;strong&gt;sequence diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
sequenceDiagram
Alice-&amp;gt;&amp;gt;John: Hello John, how are you?
loop Healthcheck
    John-&amp;gt;&amp;gt;John: Fight against hypochondria
end
Note right of John: Rational thoughts!
John--&amp;gt;&amp;gt;Alice: Great!
John-&amp;gt;&amp;gt;Bob: How about you?
Bob--&amp;gt;&amp;gt;John: Jolly good!
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;sequenceDiagram
Alice-&amp;gt;&amp;gt;John: Hello John, how are you?
loop Healthcheck
    John-&amp;gt;&amp;gt;John: Fight against hypochondria
end
Note right of John: Rational thoughts!
John--&amp;gt;&amp;gt;Alice: Great!
John-&amp;gt;&amp;gt;Bob: How about you?
Bob--&amp;gt;&amp;gt;John: Jolly good!
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An example &lt;strong&gt;Gantt diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
gantt
section Section
Completed :done,    des1, 2014-01-06,2014-01-08
Active        :active,  des2, 2014-01-07, 3d
Parallel 1   :         des3, after des1, 1d
Parallel 2   :         des4, after des1, 1d
Parallel 3   :         des5, after des3, 1d
Parallel 4   :         des6, after des4, 1d
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;gantt
section Section
Completed :done,    des1, 2014-01-06,2014-01-08
Active        :active,  des2, 2014-01-07, 3d
Parallel 1   :         des3, after des1, 1d
Parallel 2   :         des4, after des1, 1d
Parallel 3   :         des5, after des3, 1d
Parallel 4   :         des6, after des4, 1d
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An example &lt;strong&gt;class diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
classDiagram
Class01 &amp;lt;|-- AveryLongClass : Cool
&amp;lt;&amp;lt;interface&amp;gt;&amp;gt; Class01
Class09 --&amp;gt; C2 : Where am i?
Class09 --* C3
Class09 --|&amp;gt; Class07
Class07 : equals()
Class07 : Object[] elementData
Class01 : size()
Class01 : int chimp
Class01 : int gorilla
class Class10 {
  &amp;lt;&amp;lt;service&amp;gt;&amp;gt;
  int id
  size()
}
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;classDiagram
Class01 &amp;lt;|-- AveryLongClass : Cool
&amp;lt;&amp;lt;interface&amp;gt;&amp;gt; Class01
Class09 --&amp;gt; C2 : Where am i?
Class09 --* C3
Class09 --|&amp;gt; Class07
Class07 : equals()
Class07 : Object[] elementData
Class01 : size()
Class01 : int chimp
Class01 : int gorilla
class Class10 {
  &amp;lt;&amp;lt;service&amp;gt;&amp;gt;
  int id
  size()
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An example &lt;strong&gt;state diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
stateDiagram
[*] --&amp;gt; Still
Still --&amp;gt; [*]
Still --&amp;gt; Moving
Moving --&amp;gt; Still
Moving --&amp;gt; Crash
Crash --&amp;gt; [*]
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;stateDiagram
[*] --&amp;gt; Still
Still --&amp;gt; [*]
Still --&amp;gt; Moving
Moving --&amp;gt; Still
Moving --&amp;gt; Crash
Crash --&amp;gt; [*]
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;todo-lists&#34;&gt;Todo lists&lt;/h3&gt;
&lt;p&gt;You can even write your todo lists in Academic too:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;- [x] Write math example
- [x] Write diagram example
- [ ] Do something else
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Write math example&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Write diagram example&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Do something else&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;tables&#34;&gt;Tables&lt;/h3&gt;
&lt;p&gt;Represent your data in tables:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;| First Header  | Second Header |
| ------------- | ------------- |
| Content Cell  | Content Cell  |
| Content Cell  | Content Cell  |
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;First Header&lt;/th&gt;
&lt;th&gt;Second Header&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Content Cell&lt;/td&gt;
&lt;td&gt;Content Cell&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Content Cell&lt;/td&gt;
&lt;td&gt;Content Cell&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;asides&#34;&gt;Asides&lt;/h3&gt;
&lt;p&gt;Academic supports a 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/#alerts&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;shortcode for asides&lt;/a&gt;, also referred to as &lt;em&gt;notices&lt;/em&gt;, &lt;em&gt;hints&lt;/em&gt;, or &lt;em&gt;alerts&lt;/em&gt;. By wrapping a paragraph in &lt;code&gt;{{% alert note %}} ... {{% /alert %}}&lt;/code&gt;, it will render as an aside.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% alert note %}}
A Markdown aside is useful for displaying notices, hints, or definitions to your readers.
{{% /alert %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    A Markdown aside is useful for displaying notices, hints, or definitions to your readers.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;spoilers&#34;&gt;Spoilers&lt;/h3&gt;
&lt;p&gt;Add a spoiler to a page to reveal text, such as an answer to a question, after a button is clicked.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; spoiler text=&amp;quot;Click to view the spoiler&amp;quot; &amp;gt;}}
You found me!
{{&amp;lt; /spoiler &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;spoiler &#34; &gt;
  &lt;p&gt;
    &lt;a class=&#34;btn btn-primary&#34; data-toggle=&#34;collapse&#34; href=&#34;#spoiler-1&#34; role=&#34;button&#34; aria-expanded=&#34;false&#34; aria-controls=&#34;spoiler-1&#34;&gt;
      Click to view the spoiler
    &lt;/a&gt;
  &lt;/p&gt;
  &lt;div class=&#34;collapse card &#34; id=&#34;spoiler-1&#34;&gt;
    &lt;div class=&#34;card-body&#34;&gt;
      You found me!
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;icons&#34;&gt;Icons&lt;/h3&gt;
&lt;p&gt;Academic enables you to use a wide range of 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/page-builder/#icons&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;icons from &lt;em&gt;Font Awesome&lt;/em&gt; and &lt;em&gt;Academicons&lt;/em&gt;&lt;/a&gt; in addition to 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/#emojis&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;emojis&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here are some examples using the &lt;code&gt;icon&lt;/code&gt; shortcode to render icons:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; icon name=&amp;quot;terminal&amp;quot; pack=&amp;quot;fas&amp;quot; &amp;gt;}} Terminal  
{{&amp;lt; icon name=&amp;quot;python&amp;quot; pack=&amp;quot;fab&amp;quot; &amp;gt;}} Python  
{{&amp;lt; icon name=&amp;quot;r-project&amp;quot; pack=&amp;quot;fab&amp;quot; &amp;gt;}} R
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;p&gt;
  &lt;i class=&#34;fas fa-terminal  pr-1 fa-fw&#34;&gt;&lt;/i&gt; Terminal&lt;br&gt;

  &lt;i class=&#34;fab fa-python  pr-1 fa-fw&#34;&gt;&lt;/i&gt; Python&lt;br&gt;

  &lt;i class=&#34;fab fa-r-project  pr-1 fa-fw&#34;&gt;&lt;/i&gt; R&lt;/p&gt;
&lt;h3 id=&#34;did-you-find-this-page-helpful-consider-sharing-it-&#34;&gt;Did you find this page helpful? Consider sharing it üôå&lt;/h3&gt;
</description>
    </item>
    
    <item>
      <title>An example preprint / working paper</title>
      <link>/publication/preprint/</link>
      <pubDate>Sun, 07 Apr 2019 00:00:00 +0000</pubDate>
      <guid>/publication/preprint/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Slides&lt;/em&gt; button above to demo Academic&amp;rsquo;s Markdown slides feature.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Supplementary notes can be added here, including 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code and math&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Display Jupyter Notebooks with Academic</title>
      <link>/post/prev/jupyter/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>/post/prev/jupyter/</guid>
      <description>&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from IPython.core.display import Image
Image(&#39;https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./index_1_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(&amp;quot;Welcome to Academic!&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Welcome to Academic!
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;install-python-and-jupyterlab&#34;&gt;Install Python and JupyterLab&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.anaconda.com/distribution/#download-section&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Install Anaconda&lt;/a&gt; which includes Python 3 and JupyterLab.&lt;/p&gt;
&lt;p&gt;Alternatively, install JupyterLab with &lt;code&gt;pip3 install jupyterlab&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;create-or-upload-a-jupyter-notebook&#34;&gt;Create or upload a Jupyter notebook&lt;/h2&gt;
&lt;p&gt;Run the following commands in your Terminal, substituting &lt;code&gt;&amp;lt;MY-WEBSITE-FOLDER&amp;gt;&lt;/code&gt; and &lt;code&gt;&amp;lt;SHORT-POST-TITLE&amp;gt;&lt;/code&gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir -p &amp;lt;MY-WEBSITE-FOLDER&amp;gt;/content/post/&amp;lt;SHORT-POST-TITLE&amp;gt;/
cd &amp;lt;MY-WEBSITE-FOLDER&amp;gt;/content/post/&amp;lt;SHORT-POST-TITLE&amp;gt;/
jupyter lab index.ipynb
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;jupyter&lt;/code&gt; command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.&lt;/p&gt;
&lt;h2 id=&#34;edit-your-post-metadata&#34;&gt;Edit your post metadata&lt;/h2&gt;
&lt;p&gt;The first cell of your Jupter notebook will contain your post metadata (
&lt;a href=&#34;https://sourcethemes.com/academic/docs/front-matter/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;front matter&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;In Jupter, choose &lt;em&gt;Markdown&lt;/em&gt; as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;---
title: My post&#39;s title
date: 2019-09-01

# Put any other Academic metadata here...
---
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Edit the metadata of your post, using the 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;documentation&lt;/a&gt; as a guide to the available options.&lt;/p&gt;
&lt;p&gt;To set a 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#featured-image&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;featured image&lt;/a&gt;, place an image named &lt;code&gt;featured&lt;/code&gt; into your post&amp;rsquo;s folder.&lt;/p&gt;
&lt;p&gt;For other tips, such as using math, see the guide on 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;writing content with Academic&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;convert-notebook-to-markdown&#34;&gt;Convert notebook to Markdown&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;example&#34;&gt;Example&lt;/h2&gt;
&lt;p&gt;This post was created with Jupyter. The orginal files can be found at &lt;a href=&#34;https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter&#34;&gt;https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-academic&#34;&gt;Create slides in Markdown with Academic&lt;/h1&gt;
&lt;p&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Academic&lt;/a&gt; | 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;fragment &#34; &gt;
One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
&lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
Three
&lt;/span&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/img/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/img/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;
&lt;a href=&#34;https://spectrum.chat/academic&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Privacy Policy</title>
      <link>/privacy/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>/privacy/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Terms</title>
      <link>/terms/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>/terms/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>External Project</title>
      <link>/project/external-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>/project/external-project/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Internal Project</title>
      <link>/project/internal-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>/project/internal-project/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Academic: the website builder for Hugo</title>
      <link>/post/prev/getting-started/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 +0000</pubDate>
      <guid>/post/prev/getting-started/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Create a free website with Academic using Markdown, Jupyter, or RStudio. Choose a beautiful color theme and build anything with the Page Builder - over 40 &lt;em&gt;widgets&lt;/em&gt;, &lt;em&gt;themes&lt;/em&gt;, and &lt;em&gt;language packs&lt;/em&gt; included!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://academic-demo.netlify.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Check out the latest &lt;strong&gt;demo&lt;/strong&gt;&lt;/a&gt; of what you&amp;rsquo;ll get in less than 10 minutes, or 
&lt;a href=&#34;https://sourcethemes.com/academic/#expo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;view the &lt;strong&gt;showcase&lt;/strong&gt;&lt;/a&gt; of personal, project, and business sites.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;üëâ 
&lt;a href=&#34;#install&#34;&gt;&lt;strong&gt;Get Started&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;üìö 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;View the &lt;strong&gt;documentation&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;üí¨ 
&lt;a href=&#34;https://discourse.gohugo.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Ask a question&lt;/strong&gt; on the forum&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;üë• 
&lt;a href=&#34;https://spectrum.chat/academic&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Chat with the &lt;strong&gt;community&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;üê¶ Twitter: 
&lt;a href=&#34;https://twitter.com/source_themes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@source_themes&lt;/a&gt; 
&lt;a href=&#34;https://twitter.com/GeorgeCushen&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@GeorgeCushen&lt;/a&gt; 
&lt;a href=&#34;https://twitter.com/search?q=%23MadeWithAcademic&amp;amp;src=typd&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;#MadeWithAcademic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;üí° 
&lt;a href=&#34;https://github.com/gcushen/hugo-academic/issues&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Request a &lt;strong&gt;feature&lt;/strong&gt; or report a &lt;strong&gt;bug&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;‚¨ÜÔ∏è &lt;strong&gt;Updating?&lt;/strong&gt; View the 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/update/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Update Guide&lt;/a&gt; and 
&lt;a href=&#34;https://sourcethemes.com/academic/updates/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Release Notes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;‚ù§Ô∏è &lt;strong&gt;Support development&lt;/strong&gt; of Academic:
&lt;ul&gt;
&lt;li&gt;‚òïÔ∏è 
&lt;a href=&#34;https://paypal.me/cushen&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Donate a coffee&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;üíµ 
&lt;a href=&#34;https://www.patreon.com/cushen&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Become a backer on &lt;strong&gt;Patreon&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;üñºÔ∏è 
&lt;a href=&#34;https://www.redbubble.com/people/neutreno/works/34387919-academic&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Decorate your laptop or journal with an Academic &lt;strong&gt;sticker&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;üëï 
&lt;a href=&#34;https://academic.threadless.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wear the &lt;strong&gt;T-shirt&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;üë©‚Äçüíª 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/contribute/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Contribute&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;















&lt;figure id=&#34;figure-academic-is-mobile-first-with-a-responsive-design-to-ensure-that-your-site-looks-stunning-on-every-device&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://raw.githubusercontent.com/gcushen/hugo-academic/master/academic.png&#34; data-caption=&#34;Academic is mobile first with a responsive design to ensure that your site looks stunning on every device.&#34;&gt;


  &lt;img src=&#34;https://raw.githubusercontent.com/gcushen/hugo-academic/master/academic.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Academic is mobile first with a responsive design to ensure that your site looks stunning on every device.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;Key features:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Page builder&lt;/strong&gt; - Create &lt;em&gt;anything&lt;/em&gt; with 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/page-builder/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;widgets&lt;/strong&gt;&lt;/a&gt; and 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;elements&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Edit any type of content&lt;/strong&gt; - Blog posts, publications, talks, slides, projects, and more!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Create content&lt;/strong&gt; in 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Markdown&lt;/strong&gt;&lt;/a&gt;, 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/jupyter/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Jupyter&lt;/strong&gt;&lt;/a&gt;, or 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/install/#install-with-rstudio&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;RStudio&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Plugin System&lt;/strong&gt; - Fully customizable 
&lt;a href=&#34;https://sourcethemes.com/academic/themes/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;color&lt;/strong&gt; and &lt;strong&gt;font themes&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Display Code and Math&lt;/strong&gt; - Code highlighting and 
&lt;a href=&#34;https://en.wikibooks.org/wiki/LaTeX/Mathematics&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LaTeX math&lt;/a&gt; supported&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Integrations&lt;/strong&gt; - 
&lt;a href=&#34;https://analytics.google.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google Analytics&lt;/a&gt;, 
&lt;a href=&#34;https://disqus.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Disqus commenting&lt;/a&gt;, Maps, Contact Forms, and more!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Beautiful Site&lt;/strong&gt; - Simple and refreshing one page design&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Industry-Leading SEO&lt;/strong&gt; - Help get your website found on search engines and social media&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Media Galleries&lt;/strong&gt; - Display your images and videos with captions in a customizable gallery&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mobile Friendly&lt;/strong&gt; - Look amazing on every screen with a mobile friendly version of your site&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multi-language&lt;/strong&gt; - 15+ language packs including English, ‰∏≠Êñá, and Portugu√™s&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multi-user&lt;/strong&gt; - Each author gets their own profile page&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Privacy Pack&lt;/strong&gt; - Assists with GDPR&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stand Out&lt;/strong&gt; - Bring your site to life with animation, parallax backgrounds, and scroll effects&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;One-Click Deployment&lt;/strong&gt; - No servers. No databases. Only files.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;p&gt;Academic comes with &lt;strong&gt;automatic day (light) and night (dark) mode&lt;/strong&gt; built-in. Alternatively, visitors can  choose their preferred mode - click the sun/moon icon in the top right of the 
&lt;a href=&#34;https://academic-demo.netlify.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Demo&lt;/a&gt; to see it in action! Day/night mode can also be disabled by the site admin in &lt;code&gt;params.toml&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/themes/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Choose a stunning &lt;strong&gt;theme&lt;/strong&gt; and &lt;strong&gt;font&lt;/strong&gt;&lt;/a&gt; for your site. Themes are fully 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/customization/#custom-theme&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;customizable&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;ecosystem&#34;&gt;Ecosystem&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;
&lt;a href=&#34;https://github.com/sourcethemes/academic-admin&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Academic Admin&lt;/a&gt;:&lt;/strong&gt; An admin tool to import publications from BibTeX or import assets for an offline site&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;
&lt;a href=&#34;https://github.com/sourcethemes/academic-scripts&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Academic Scripts&lt;/a&gt;:&lt;/strong&gt; Scripts to help migrate content to new versions of Academic&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;install&#34;&gt;Install&lt;/h2&gt;
&lt;p&gt;You can choose from one of the following four methods to install:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/docs/install/#install-with-web-browser&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;one-click install using your web browser (recommended)&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/docs/install/#install-with-git&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;install on your computer using &lt;strong&gt;Git&lt;/strong&gt; with the Command Prompt/Terminal app&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/docs/install/#install-with-zip&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;install on your computer by downloading the &lt;strong&gt;ZIP files&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/docs/install/#install-with-rstudio&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;install on your computer with &lt;strong&gt;RStudio&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Then 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/get-started/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;personalize and deploy your new site&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;updating&#34;&gt;Updating&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/docs/update/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;View the Update Guide&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Feel free to &lt;em&gt;star&lt;/em&gt; the project on 
&lt;a href=&#34;https://github.com/gcushen/hugo-academic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Github&lt;/a&gt; to help keep track of 
&lt;a href=&#34;https://sourcethemes.com/academic/updates&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;updates&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;license&#34;&gt;License&lt;/h2&gt;
&lt;p&gt;Copyright 2016-present 
&lt;a href=&#34;https://georgecushen.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;George Cushen&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Released under the 
&lt;a href=&#34;https://github.com/gcushen/hugo-academic/blob/master/LICENSE.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MIT&lt;/a&gt; license.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An example journal article</title>
      <link>/publication/journal-article/</link>
      <pubDate>Tue, 01 Sep 2015 00:00:00 +0000</pubDate>
      <guid>/publication/journal-article/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Slides&lt;/em&gt; button above to demo Academic&amp;rsquo;s Markdown slides feature.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Supplementary notes can be added here, including 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code and math&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hello R Markdown</title>
      <link>/post/prev/2015-07-23-r-rmarkdown/</link>
      <pubDate>Thu, 23 Jul 2015 21:13:14 -0500</pubDate>
      <guid>/post/prev/2015-07-23-r-rmarkdown/</guid>
      <description>


&lt;div id=&#34;r-markdown&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;R Markdown&lt;/h1&gt;
&lt;p&gt;This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see &lt;a href=&#34;http://rmarkdown.rstudio.com&#34; class=&#34;uri&#34;&gt;http://rmarkdown.rstudio.com&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can embed an R code chunk like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(cars)
##      speed           dist       
##  Min.   : 4.0   Min.   :  2.00  
##  1st Qu.:12.0   1st Qu.: 26.00  
##  Median :15.0   Median : 36.00  
##  Mean   :15.4   Mean   : 42.98  
##  3rd Qu.:19.0   3rd Qu.: 56.00  
##  Max.   :25.0   Max.   :120.00
fit &amp;lt;- lm(dist ~ speed, data = cars)
fit
## 
## Call:
## lm(formula = dist ~ speed, data = cars)
## 
## Coefficients:
## (Intercept)        speed  
##     -17.579        3.932&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;including-plots&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Including Plots&lt;/h1&gt;
&lt;p&gt;You can also embed plots. See Figure &lt;a href=&#34;#fig:pie&#34;&gt;1&lt;/a&gt; for example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;par(mar = c(0, 1, 0, 1))
pie(
  c(280, 60, 20),
  c(&amp;#39;Sky&amp;#39;, &amp;#39;Sunny side of pyramid&amp;#39;, &amp;#39;Shady side of pyramid&amp;#39;),
  col = c(&amp;#39;#0292D8&amp;#39;, &amp;#39;#F7EA39&amp;#39;, &amp;#39;#C4B632&amp;#39;),
  init.angle = -50, border = NA
)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:pie&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/post/2015-07-23-r-rmarkdown_files/figure-html/pie-1.png&#34; alt=&#34;A fancy pie chart.&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: A fancy pie chart.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>An example conference paper</title>
      <link>/publication/conference-paper/</link>
      <pubDate>Mon, 01 Jul 2013 00:00:00 +0000</pubDate>
      <guid>/publication/conference-paper/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Slides&lt;/em&gt; button above to demo Academic&amp;rsquo;s Markdown slides feature.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Supplementary notes can be added here, including 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code and math&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/post/clusterizar-disenos/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/post/clusterizar-disenos/</guid>
      <description>&lt;h1 id=&#34;clusterize-design-patterns&#34;&gt;Clusterize design patterns&lt;/h1&gt;
&lt;p&gt;¬øHow can I find patterns in design?&lt;/p&gt;
&lt;p&gt;With so many adds around, one would think that that process is quite standardized
but it remains, most times, a manual labor. This is, I believe mostly,
because of how competitive that market is. To stand out, graphic designers have
still a lot of work&lt;/p&gt;
&lt;p&gt;But that doesn&amp;rsquo;t mean that we can&amp;rsquo;t find design patterns, after all, after
a few thousend design even the best designer tend to have trends.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lucasenrich.netlify.com/en/post/clusterizar-disenos/&#34;&gt;Read more &lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/banner-example.png&#34; width=&#34;400px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Input data&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This problem had, originally, many houndred of designs, in this example
I will use just a few made ad hoc for this purposes because
in the end, clustering algorithms doesn&amp;rsquo;t need that many data to
be effective.&lt;/p&gt;
&lt;p&gt;Given these are manual examples, it&amp;rsquo;s all about sizes and shapes. I
left behind fonts, content of the images and other. What I look for is
pattern in the layout of the elements in the banner&lt;/p&gt;
&lt;p&gt;Once extracted, data came in this form:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/input_data.png&#34; width=&#34;65%&#34; style=&#34;float:left; padding:20px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;font size = 3&gt; &lt;em&gt;y&lt;/em&gt; : Distance from the top &lt;/font&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;font size = 3&gt; &lt;em&gt;x&lt;/em&gt; : Distance from the left &lt;/font&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;font size = 3&gt; &lt;em&gt;w&lt;/em&gt; : Width &lt;/font&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;font size = 3&gt; &lt;em&gt;h&lt;/em&gt; : Height &lt;/font&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If we have 50 exameples, with 3 elements each, and 4 variables per element
the shape of the input file is 50‚ÄÖ√ó‚ÄÖ3‚ÄÖ√ó‚ÄÖ4. Algorithms like I used like
2D data better, so I spread them to 50‚ÄÖ√ó‚ÄÖ12 for which:&lt;/p&gt;
&lt;p&gt;First, iterate file by file and transform each from 1‚ÄÖ√ó‚ÄÖ3‚ÄÖ√ó‚ÄÖ4 to
1‚ÄÖ√ó‚ÄÖ12. In R code:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;library(tidyverse)
cols_used = c(&#39;element_top&#39;, &#39;element_left&#39;, &#39;element_width&#39;, &#39;element_height&#39;)
spread_file&amp;lt;-function(data, cols_used){
  cols_used_a = c(&#39;element_name&#39;,cols_used)
  y=data[cols_used]
  h = data[cols_used_a]
  z=c(1,1,1,1)
  for(i in 1:nrow(y)) {
    z = cbind(z,y[i,])
  }
  z = z[1,-1] 
  
  newcols &amp;lt;- c()
  for (i in  h[&#39;element_name&#39;]){
    newcols&amp;lt;-cbind(newcols,paste(i,cols_used[1], sep = &#39;.&#39;))
    newcols&amp;lt;-cbind(newcols,paste(i,cols_used[2], sep = &#39;.&#39;))
    newcols&amp;lt;-cbind(newcols,paste(i,cols_used[3], sep = &#39;.&#39;))
    newcols&amp;lt;-cbind(newcols,paste(i,cols_used[4], sep = &#39;.&#39;))
  }
  newcols2&amp;lt;-c()
  for(i in 1:nrow(newcols)) {
    for(j in 1:4){
      newcols2&amp;lt;-c(newcols2,newcols[i,j])
    }
  }
  colnames(z)&amp;lt;-newcols2
  n&amp;lt;-as_vector(data[&#39;id&#39;])
  z[&#39;id&#39;]&amp;lt;-n[1]
  z
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And then iterate to transform this&lt;/p&gt;
&lt;p&gt;$$\begin{bmatrix} elem1 &amp;amp; y_1 &amp;amp; x_1 &amp;amp; w_1 &amp;amp; h_1 \\   elem2 &amp;amp; y_2 &amp;amp; x_2 &amp;amp; w_2 &amp;amp; h_2  \\   \vdots \\   elemk &amp;amp; y_2 &amp;amp; x_k &amp;amp; w_k &amp;amp; h_k \end{bmatrix}$$
in this:&lt;/p&gt;
&lt;p&gt;$$\begin{bmatrix}
id.1 &amp;amp; elem.1.x &amp;amp; elem.1.y &amp;amp; elem.1.h &amp;amp; elem.1.w &amp;amp; &amp;hellip; &amp;amp; elem.k.w
\end{bmatrix}$$
This way, you can stack them into:&lt;/p&gt;
&lt;p&gt;$$\begin{bmatrix} id.1 &amp;amp; elem.1.x &amp;amp; elem.1.y &amp;amp; elem.1.h &amp;amp; elem.1.w &amp;amp; &amp;hellip; &amp;amp; elem.k.w \\ id.2 &amp;amp; elem.1.x &amp;amp; elem.1.y &amp;amp; elem.1.h &amp;amp; elem.1.w &amp;amp; &amp;hellip; &amp;amp; elem.k.w \\ \vdots \\ id.N &amp;amp; elem.1.x &amp;amp; elem.1.y &amp;amp; elem.1.h &amp;amp; elem.1.w &amp;amp; &amp;hellip; &amp;amp; elem.k.w \end{bmatrix}$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;font size = 3&gt; Dimentionality reduction + Clustering &lt;/font&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This most direct form of clusterization for this porpuses is &lt;strong&gt;dbscan&lt;/strong&gt; and
run it on our transform base. This didn&amp;rsquo;t work as expected so first I
used a technique to reduce dimensionality and then do the clustering.&lt;/p&gt;
&lt;p&gt;PCA and t-SNE are the most popular algorithms in dimensionality reduction
but UMAP is the new kid in the block (well it has almost 2 years now)
with some fancy math behind it, it preserves global and local structures.
and works faster using graphs. One thing to keep in mind when using it is that at one
point uses a random procedure which makes it that each time you run it
the mapping into 2D will look slightly different, but every point is
similary close to others in each iteration. To prevent this, set.seed()
is the way to go.&lt;/p&gt;
&lt;p&gt;And finally:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;library(umap)
library(dbscan)
umap_data&amp;lt;- umap(data)
cl &amp;lt;-hdbscan(x = umap_data, minPts = 3)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This worked better than with the full dimentions, but not quite as needed. Its time to&amp;hellip;&lt;/p&gt;
&lt;p&gt;&lt;font size = 3&gt; Transform and normalice&lt;/p&gt;
&lt;p&gt;Most common option &lt;/font&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;font size = 2&gt; Standarization (z-score): Represents the number of standard
deviations up or down of resulting value. &lt;strong&gt;Useful for normally distributed
variables&lt;/strong&gt;
&lt;/font&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;font size = 2&gt; Normalization (min-max scaler): It allows to transform the data
into values between 0 and 1. &lt;strong&gt;Useful when working with variables with different
orders of magnitude&lt;/strong&gt;
&lt;/font&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;/img/normaliz_data.png&#34; width=&#34;65%&#34; style=&#34;float:left; padding:20px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Can I use this transformations in this data?&lt;/strong&gt;&lt;/p&gt;
&lt;font size = 4&gt;
&lt;ul&gt;
&lt;li&gt;Not really, what this variables describe are absolute positions in space
and are quite linked to one-another.&lt;/li&gt;
&lt;/ul&gt;
&lt;/font&gt;
&lt;font size = 4&gt;
&lt;ul&gt;
&lt;li&gt;What can I do? Instead of using absolute positions and dimentions,
lets use its &lt;em&gt;relative&lt;/em&gt;, what I&amp;rsquo;ll call &amp;ldquo;geometric normalization&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- --&gt;
&lt;pre&gt;&lt;code&gt;normalize_geometric&amp;lt;-function(df){
  df[&#39;total_area&#39;]&amp;lt;-max(df[&#39;element_height&#39;])*max(df[&#39;element_width&#39;])

  df[&#39;rel_area&#39;]&amp;lt;-df[&#39;element_height&#39;]*df[&#39;element_width&#39;]/df[&#39;total_area&#39;]
  
  df[&#39;orientation&#39;]&amp;lt;-df[&#39;element_height&#39;]/df[&#39;element_width&#39;]
  
  df[&#39;element_top_relative&#39;]&amp;lt;-df[&#39;element_top&#39;]/max(df[&#39;element_height&#39;])
  
  df[&#39;element_left_relative&#39;]&amp;lt;-df[&#39;element_left&#39;]/max(df[&#39;element_width&#39;])
  
  df
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/font&gt;
&lt;ul&gt;
&lt;li&gt;x&amp;rsquo; is now the proportion of x in respecto the total width of the canvas&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;font size = 3&gt; &lt;em&gt;My new variable is x&amp;rsquo;, red line divided the blue one&lt;/em&gt; &lt;/font&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/x_demo_plot.jpeg&#34; width=&#34;65%&#34; style=&#34;float:left; padding:20px&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;y&amp;rsquo; is now the proportion of x in respecto the total height of the canvas&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;font size = 3&gt; &lt;em&gt;My new variable is y&amp;rsquo;, red line divided the blue one&lt;/em&gt; &lt;/font&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/demo_plot_y.jpeg&#34; width=&#34;65%&#34; style=&#34;float:left; padding:20px&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;areaRelativa is the proportion of the canvas the element occupies&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;font size = 3&gt; &lt;em&gt;My new variable areaRelativa is: the are of the small rectangle divided
divided the area of the big one&lt;/em&gt; &lt;/font&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/area_plot.jpeg&#34; width=&#34;65%&#34; style=&#34;float:left; padding:20px&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;disposition is to know if the elmenet in horizontal position, vertical or if
it is a square&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;font size = 3&gt; &lt;em&gt;My new variable disposicion es: heigth/width&lt;/em&gt; &lt;/font&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/rectangular.png&#34; width=&#34;30%&#34; style=&#34;float:center; padding:0% 35%&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;p&gt;To begin to analize the results, every &amp;ldquo;spread&amp;rdquo; has to have a &amp;ldquo;gather&amp;rdquo;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gather_file&amp;lt;-function(gdf){
  x&amp;lt;-strsplit(colnames(gdf), &#39;\\.&#39;)
  
  element_name=unique(unlist(map(x, 1)))
  original_cols=unique(unlist(map(x, 2)))
  gdf1&amp;lt;-data.frame(element_name)
  gdf1[original_cols[1]]&amp;lt;-0
  gdf1[original_cols[2]]&amp;lt;-0
  gdf1[original_cols[3]]&amp;lt;-0
  gdf1[original_cols[4]]&amp;lt;-0
  
  
  
  rel_area&amp;lt;-c()
  orientation&amp;lt;-c()
  element_top_relative&amp;lt;-c()
  element_left_relative&amp;lt;-c()
  
  for(i in seq(from=1, to=length(gdf), by=4)){
    #  stuff, such as
    rel_area=c(rel_area,gdf[i])
    orientation=c(orientation,gdf[i+1])
    element_top_relative = c(element_top_relative,gdf[i+2])
    element_left_relative = c(element_left_relative,gdf[i+3])
  }
  
  gdf1[&#39;rel_area&#39;]=as_vector(unlist(rel_area))
  gdf1[&#39;orientation&#39;]=as_vector(unlist(orientation))
  gdf1[&#39;element_top_relative&#39;]=as_vector(unlist(element_top_relative))
  gdf1[&#39;element_left_relative&#39;]=as_vector(unlist(element_left_relative))
  gdf1}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&amp;rsquo;s first see how the clustering works with and without geometric normalization&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/unnamed-chunk-12-1.png&#34; width=&#34;30%&#34; style=&#34;float:center; padding:0% 35%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And finally, examples of each group:&lt;/p&gt;
&lt;p&gt;First cluster:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/c1img.jpeg&#34; width=&#34;30%&#34; style=&#34;float:center; padding:0% 35%&#34; /&gt;
000003.png&lt;/p&gt;
&lt;p&gt;Second cluster:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/cl2img.jpeg&#34; width=&#34;30%&#34; style=&#34;float:center; padding:0% 35%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Third:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/cl3img.jpeg&#34; width=&#34;30%&#34; style=&#34;float:center; padding:0% 35%&#34; /&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title></title>
      <link>/post/dedupl/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/post/dedupl/</guid>
      <description>&lt;h1 id=&#34;de-duplicaci√≥n-de-avisos&#34;&gt;De-duplicaci√≥n de Avisos&lt;/h1&gt;
&lt;p&gt;Cualquiera que haya hecho un curso introductorio o le√≠do un libro de
Ciencia de Datos sabe que se dice mucho que la limpieza de un dataset
es, por lo menos el 80% del trabajo y luego el modelado. Pero eso no
quiere decir que no hagan falta t√©cnicas propias del modelado para
limpiar un dataset.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lucasenrich.netlify.com/post/dedupl/&#34;&gt;Read more &lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Con un scrap hecho a ZonaProp, de las unidades en alquiler en Recoleta
en febrero 2020, luego de una exahustiva limpieza de unificaci√≥n de la
moneda, de correcci√≥n de datos impl√≠citos (NA&amp;rsquo;s que implicaban un dato,
por ejemplo, cocheras-si es NA, cocheras=0).&lt;/p&gt;
&lt;p&gt;El problema que qued√≥ fue que el resultado es una base de datos de
&lt;em&gt;avisos&lt;/em&gt;, pero, ¬øque pasa si yo quiero que mi base de datos sea de
&lt;em&gt;inmuebles&lt;/em&gt;? El problema que me encuentro es que hay avisos duplicados,
ya sea porque vuelven a estar publicados o porque un mismo inmueble es
publicado por m√°s de una inmobiliaria.&lt;/p&gt;
&lt;p&gt;¬øC√≥mo se pueden detectar sistematicamente esas duplicaciones? Debajo hay
un m√©todo posible&lt;/p&gt;
&lt;h3 id=&#34;los-datos&#34;&gt;Los Datos&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;library(tidyverse)
alqs&amp;lt;-read_csv(&amp;quot;alq_feb20_recoleta.csv&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Bien, este es el dataset. Una primera idea ser√≠a: si dos publicaciones
se parecen lo suficiente, sospechamos que son la misma.&lt;/p&gt;
&lt;p&gt;Las columnas son&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;Columna&lt;/th&gt;
&lt;th&gt;Descrpci√≥n&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;WEB&lt;/td&gt;
&lt;td&gt;La url de la publicaci√≥n&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Provincia&lt;/td&gt;
&lt;td&gt;La provincia de la publicaci√≥n&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Tipo_Op&lt;/td&gt;
&lt;td&gt;Si corresponde a venta o alquiler&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Tipo&lt;/td&gt;
&lt;td&gt;Si es casa, comercio,oficina, PH, departamento, etc&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Zona&lt;/td&gt;
&lt;td&gt;El barrio, para CABA, el municipio para las provincias&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Direcci√≥n&lt;/td&gt;
&lt;td&gt;La direcci√≥n de la publicaci√≥n&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Latitud y Longittud&lt;/td&gt;
&lt;td&gt;Georreferencia&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Inmobiliaria&lt;/td&gt;
&lt;td&gt;Quien est√° publicando&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Tiempo&lt;/td&gt;
&lt;td&gt;Cuanto tiempo lleva publicado en d√≠as&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Cochera&lt;/td&gt;
&lt;td&gt;Si tiene cochera, boolean&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Expensas&lt;/td&gt;
&lt;td&gt;Cuanto se paga de expensas&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Prices&lt;/td&gt;
&lt;td&gt;El precio de venta/alquiler&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Antig√ºedad&lt;/td&gt;
&lt;td&gt;Cuantos a√±os tiene de construido&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Metros&lt;/td&gt;
&lt;td&gt;Tama√±o en metros cuadrados&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Ambientes&lt;/td&gt;
&lt;td&gt;Cantidad de Ambientes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Descripci√≥n&lt;/td&gt;
&lt;td&gt;El texto de la descripci√≥n&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Ba√±os&lt;/td&gt;
&lt;td&gt;Cantidad de ba√±os&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Ahora bien, cualquier procedimiento de detecci√≥n de duplicados requiere
necesariamente cierta flexibilidad, sino buscamos aquellos identicos y
listo; pero la realidad es que la duplicaci√≥n en general va a tener un
motivo en concreto, sea por correcci√≥n de alg√∫n dato en particular, sea
por ponerlo en otra inmobiliaria, sea por cambio de la descripci√≥n para
que sea m√°s atractiva. Pero por otro lado, revisar todos los pares
posible nos va a llevar a que, si &lt;em&gt;N&lt;/em&gt; es la cantidad de publicaciones en
el dataset, los chequeos sean &lt;em&gt;N&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt;. Manualmente, esto, es
inviable.&lt;/p&gt;
&lt;p&gt;Entonces, lo que se puede hacer es:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Ver la tasa de variaci√≥n de las variables num√©ricas.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Verificar la distancia (aprovechando que estan georreferenciados)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ver cuanto se parecen las descripciones&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;tasa-de-variacion-de-las-variables-numericas&#34;&gt;Tasa de variacion de las variables numericas&lt;/h3&gt;
&lt;p&gt;Una opci√≥n ser√≠a considerar solo las variables que son iguales, pero eso
descarta la posibilidad que haya una correcci√≥n en los datos, ni hablar
si alguno de los datos se considera missing (&lt;em&gt;N**A&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;Una cuesti√≥n antes de arrancar con esta secci√≥n, se estar√° generando una
matriz sim√©trica para cada una de estas variables n√∫mericas. En la cual
&lt;em&gt;x&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i**j&lt;/em&gt;&lt;/sub&gt; va a ser la tasa de variaci√≥n entre las
observaciones; y por lo tanto la diagonal cuando &lt;em&gt;i&lt;/em&gt;‚ÄÑ=‚ÄÑ&lt;em&gt;j&lt;/em&gt;,
&lt;em&gt;x&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i**j&lt;/em&gt;&lt;/sub&gt;‚ÄÑ=‚ÄÑ0&lt;/p&gt;
&lt;p&gt;Empecemos&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pmx&amp;lt;-matrix(nrow=nrow(alqs1), ncol=nrow(alqs1))
for(i in 1:nrow(alqs)){
  for(j in 1:nrow(alqs)){
    h= abs(alqs3$Prices[i]-alqs3$Prices[j])/max(alqs3$Prices[i],alqs3$Prices[j], na.rm = T)
    pmx[i,j] = h
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;¬øQu√© est√° mal con esta aproximaci√≥n? Que es un loop anidado, por lo que
el Big O, es cuadr√°tico, la forma &lt;em&gt;menos&lt;/em&gt; eficiente de llenar una
matriz. Esto quiere decir, que el tiempo que tarda el terminar este loop
depende cuadr√°ticamente del tama√±o de las filas.&lt;/p&gt;
&lt;p&gt;Se puede aprovechar las operaciones vectorizadas que tiene R-Base para
quedarnos con una Big O lineal.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pmx&amp;lt;-matrix(nrow=nrow(alqs1), ncol=nrow(alqs1))
for(i in 1:nrow(alqs)){
  pmx[i,] = abs(alqs3$Prices[i]-alqs3$Prices)/max(alqs3$Prices[i],alqs3$Prices, na.rm = T)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Esto es mejor, pero R tiene su propio di√°lecto para tratar con loops y
es la facilidad que tiene para trabajar vectorialmente y la familia de
funciones de &lt;em&gt;apply&lt;/em&gt;, y de paso ponemos en pr√°ctica la m√°xima de &lt;em&gt;evitar
los loops&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rel_dif = function(a,b){
  abs(a-b)/max(a,b, na.rm = T)
}
pmx&amp;lt;-sapply(FUN = rel_dif, alqs1$Prices,alqs1$Prices)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ahora que podemos obtener la matriz de diferencias con una sola linea de
c√≥digo, hagamoslo para todoas las variables n√∫mericas.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mts.mx&amp;lt;-sapply(FUN = rel_dif, alqs1$Metros,alqs1$Metros) #Metros cuadrados

antig.pmx&amp;lt;-sapply(FUN = rel_dif, alqs1$Antiguedad,alqs1$Antiguedad) #Antig√ºedad
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Solo una cosa, lo que queremos es ver cuan cerca est√°n, pero hasta ahora
vimos la variaci√≥n, por lo que la cercacia va a estar dada por:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pmx&amp;lt;-1-as.matrix(pmx)
pmts&amp;lt;-1-as.matrix(pmts)
pantg&amp;lt;-1-as.matrix(pantg)
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;distancia-geogr√°fica&#34;&gt;Distancia geogr√°fica&lt;/h4&gt;
&lt;p&gt;Para calcular la distancia geogr√°fica vamos a estar necesitando el
paquete &lt;em&gt;geosphere&lt;/em&gt; para lo cual se usa el criterio de la distancia
entre dos puntos en una superficie esf√©rica, llamada la distancia
Haversine.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;latlongs&amp;lt;-alqs1 %&amp;gt;% select(Latitud,Longitud)
dm &amp;lt;- distm(latlongs,latlongs, fun=distHaversine)  
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;La funci√≥n llamada &lt;strong&gt;distm&lt;/strong&gt; es realmente √∫til porque viene con una
implementaci√≥n vectorizada,lo cual soluciona de entrada el problema de
los potenciales loops anidados que teniamos antes.&lt;/p&gt;
&lt;h4 id=&#34;descripci√≥n&#34;&gt;Descripci√≥n&lt;/h4&gt;
&lt;p&gt;Bueno, llegamos al punto √°lgido, y por esto me refiero a que el criterio
para determinar que tan cerca est√°n dos descripciones no es tan obvio
como la distancia o la variaci√≥n relativa de alguna variable, porque
estamos tratando ahora con variables no num√©ricas; por lo tanto antes de
realizar la comparaci√≥n necesitamos convertir a ese texto en un vector
num√©rico, para lo cual existen varias v√≠as.&lt;/p&gt;
&lt;p&gt;La utilizada en este caso fue &lt;em&gt;T**F&lt;/em&gt;‚ÄÖ‚àí‚ÄÖ&lt;em&gt;I&lt;strong&gt;D&lt;/strong&gt;F&lt;/em&gt; que significa &lt;strong&gt;&amp;ldquo;term
frequency‚Äìinverse document frequency,&amp;quot;&lt;/strong&gt;, el cual genera un vector
num√©rico ponderado por la importancia de cada palabra en el texto (term
frequency) y la frecuencia de la palabra en todos los textos (inverse
document frequency)&lt;/p&gt;
&lt;p&gt;Es decir, la ponderaci√≥n indica que no todas la palabras tienen el mismo
peso para describir una descripci√≥n, sino que hay algunas que deben
ponderarse m√°s y otras que deben ponderarse menos. En el caso de una
descripci√≥n de un inmueble, las palabras que son m√°s comunes a todas las
descripciones, como pueden ser &amp;ldquo;ba√±o&amp;rdquo; √≥ &amp;ldquo;cocina&amp;rdquo;, son ponderadas menos
que las palabras que son menos frecuentes a cada descripci√≥n, como &amp;ldquo;a
tres cuadras de la estacion Primera Junta&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Este score esta definido por
$$
TFIDF_{xy} = TF_{xy}*log\frac{N}{df}
$$
donde:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;T**F&lt;/em&gt;&lt;sub&gt;&lt;em&gt;x**y&lt;/em&gt;&lt;/sub&gt; es la frecuencia de la palabra &lt;em&gt;x&lt;/em&gt; en la
descripci√≥n &lt;em&gt;y&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;N&lt;/em&gt; es el n√∫mero total de descripciones&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;d**f&lt;/em&gt; es el n√∫mero total de documentos que contienen la palabra &lt;em&gt;x&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Por suerte, python tienen una libreria para (casi)todo, por lo que esta
vectorizaci√≥n require solo unas pocas lineas de c√≥digo;
desafortunadamente, el texto est√° &amp;ldquo;sucio&amp;rdquo; y debe ser limpiado antes de
la vectorizaci√≥n.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#Eliminar caracteres especiales y espacios innecesarios
cleanFun &amp;lt;- function(htmlString) {
  #Saco los tags de html
  t=(gsub(&amp;quot;\t&amp;quot;,&amp;quot;&amp;quot;,gsub(&amp;quot;\n&amp;quot;,&amp;quot;&amp;quot;,gsub(&amp;quot;&amp;lt;.*?&amp;gt;&amp;quot;, &amp;quot;&amp;quot;, htmlString))))
  #Lo paso a minuscula
  t=tolower(t)
  #Le saco los caracteres no alfanumericos
  t=str_replace_all(t, &amp;quot;[[:punct:]]&amp;quot;, &amp;quot; &amp;quot;)
  t
  
}
#Tokenizaci√≥n y eliminaci√≥n de stopwords
prepTx &amp;lt;- function(tx){
  t1=word_tokenizer(cleanFun(tx))
  t2 = t1[!(t1%in%stopwords(kind=&amp;quot;es&amp;quot;))]
  t2 = unlist(t2)[nchar(unlist(t2))&amp;gt;2]
  t2
  
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok, ahora que el text est√° limpio, es hora de generar la conversi√≥n a
numeros&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;library(tcR)
prep_fun &amp;lt;- cleanFun
tok_fun &amp;lt;- word_tokenizer
smp_size&amp;lt;-floor(0.75*length(descripciones))
set.seed(123)
train_ind &amp;lt;- sample(seq_len(length(descripciones)), size = smp_size)
train &amp;lt;- descripciones
it_train &amp;lt;- itoken(train, 
                   preprocessor = prep_fun, 
                   tokenizer = tok_fun,
                   progressbar = TRUE)
vocab &amp;lt;- create_vocabulary(it_train)
pruned_vocab = prune_vocabulary(vocab, term_count_min = 100,
                                doc_proportion_max = 0.5, doc_proportion_min = 0.001)
vectorizer &amp;lt;- vocab_vectorizer(pruned_vocab)
dtm_train &amp;lt;- create_dtm(it_train, vectorizer)

tfidf = TfIdf$new()
dtm_transformed = tfidf$fit_transform(dtm_train)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ahora &lt;em&gt;dtm_transformed&lt;/em&gt; es nuestra variable que contiene los vectores
numericos para cada descripci√≥n. Como son vectores, una forma sencilla
de compararlos es usando la distancia coseno.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;d1_d2_tfidf_cos_sim = sim2(x = dtm_transformed, method = &amp;quot;cosine&amp;quot;, norm = &amp;quot;l2&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Y ahora si, nuestra matriz de similitud &lt;em&gt;d1_d2_tfidf_cos_sim&lt;/em&gt; nos
permite comparar las descripciones.&lt;/p&gt;
&lt;h4 id=&#34;unificaci√≥n-de-las-matrices-de-similitud&#34;&gt;Unificaci√≥n de las matrices de similitud&lt;/h4&gt;
&lt;p&gt;Ahora que tenemos todas las matrices que comparan todos los registros
con todos los dem√°s, es hora de unificarlas.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;A&amp;lt;-pmx
B&amp;lt;-pmts
C&amp;lt;-pantg
D&amp;lt;-d1_d2_tfidf_cos_sim
E&amp;lt;-dm

colnames(A)&amp;lt;-alqs3$id
rownames(A)&amp;lt;-alqs3$id

colnames(B)&amp;lt;-alqs3$id
rownames(B)&amp;lt;-alqs3$id

colnames(C)&amp;lt;-alqs3$id
rownames(C)&amp;lt;-alqs3$id

colnames(D)&amp;lt;-alqs3$id
rownames(D)&amp;lt;-alqs3$id

colnames(E)&amp;lt;-alqs3$id
rownames(E)&amp;lt;-alqs3$id


Aa&amp;lt;-as.data.frame(as.table(A)) %&amp;gt;% distinct(Var1,Var2, .keep_all = T)
Bb&amp;lt;-as.data.frame(as.table(B)) %&amp;gt;% distinct(Var1,Var2, .keep_all = T)
Cc&amp;lt;-as.data.frame(as.table(C)) %&amp;gt;% distinct(Var1,Var2, .keep_all = T)
Dd&amp;lt;-as.data.frame(as.table(D)) %&amp;gt;% distinct(Var1,Var2, .keep_all = T)
Ee&amp;lt;-as.data.frame(as.table(E)) %&amp;gt;% distinct(Var1,Var2, .keep_all = T)


colnames(Aa)[3]=&#39;precios&#39;
colnames(Bb)[3]=&#39;metros&#39;
colnames(Cc)[3]=&#39;antiguedad&#39;
colnames(Dd)[3]=&#39;descripcion&#39;
colnames(Ee)[3]=&#39;dist_mts&#39;

AB&amp;lt;-right_join(Aa,Bb, by = c(&#39;Var1&#39;,&#39;Var2&#39;))
CD&amp;lt;-right_join(Cc,Dd, by = c(&#39;Var1&#39;,&#39;Var2&#39;))
ABCD&amp;lt;-right_join(AB,CD,by = c(&#39;Var1&#39;,&#39;Var2&#39;))
ABCDE&amp;lt;-right_join(ABCD,Ee,by = c(&#39;Var1&#39;,&#39;Var2&#39;))

ABCDE&amp;lt;-ABCDE %&amp;gt;% filter(Var1!=Var2) %&amp;gt;% as_tibble()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ahora &lt;em&gt;ABCDE&lt;/em&gt; es nuestra dataframe con todos los pares de &lt;em&gt;i**d&lt;/em&gt;‚Ä≤&lt;em&gt;s&lt;/em&gt;, y
las columnas con cada criterio de similitud se agregan en la misma fila&lt;/p&gt;
&lt;p&gt;Lo que sigue es un poco arbitrario y seguro hay mejores m√©todos para
hacerlo. Pero nuestros candidatos a duplicados son aquellos que,
decimos, cumplen los siguientes criterios (en simultaneo):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Estan a menos de 300mts entre s√≠.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tienen una variaci√≥n en Metros menor al 10%&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tienen una variaci√≥n en Precio menor al 25%&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tienen una variaci√≥n en la descripcion menor al 30%&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tienen una variaci√≥n en antig√ºedad menor al 10%&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;En todos los casos se mantienen los resultados &lt;em&gt;NA&lt;/em&gt; porque eso nos
indica que podr√≠a haberse agregado el dato.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cand_dupls&amp;lt;-ABCDE %&amp;gt;% filter(dist_mts&amp;lt;=300 | is.na(dist_mts)) %&amp;gt;% 
  filter(metros&amp;gt;0.9| is.na(metros)) %&amp;gt;% filter(precios&amp;gt;0.75| is.na(precios)) %&amp;gt;% 
  filter(descripcion&amp;gt;0.7| is.na(descripcion))%&amp;gt;% filter(antiguedad&amp;gt;0.90| is.na(antiguedad))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;El resultado de esto es de 840 pares que son potencialmente duplicados.
Lo cual es una reducci√≥n bastante dr√°stica de los 1716&lt;sup&gt;2&lt;/sup&gt; que
llevar√≠a revisar todos los registros de una base de 1716 registros.&lt;/p&gt;
&lt;p&gt;Finalmente, hay un paso m√°s que puede hacerse para que el proceso sea
m√°s robusto y es considerar la propiedad transitiva de los pares,
realizar un network analysis, lo que significa agrupar todos aquellos
id&amp;rsquo;s que tienen suficiente similitud, para eso generamos una variable
que sea 1 para aquellos pares que cumplen los criterios y 0 para
aquellos que no:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cand_dupls&amp;lt;-cand_dupls %&amp;gt;% mutate(
  potdup = case_when(
   (precios &amp;gt; 0.75 |  is.na(precios)) &amp;amp; (metros &amp;gt; 0.9 |  is.na(metros)) &amp;amp; 
     (antiguedad &amp;gt; 0.9 |  is.na(antiguedad)) &amp;amp; (descripcion &amp;gt; 0.9 |  is.na(descripcion)) &amp;amp;
     (dist_mts&amp;lt;300 | is.na(dist_mts)) ~ 1,
   T ~ 0
  )
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Lo que tenemos ahora, es un dataframe que tiene los pares que creemos
que son duplicados, estos van a ser nuestros vinculos en el analisis de
red, los &lt;em&gt;edges&lt;/em&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;edges&amp;lt;-cand_dupls %&amp;gt;% select(Var1, Var2, potdup)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Que tienen esta forma&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;ID1&lt;/th&gt;
&lt;th&gt;ID2&lt;/th&gt;
&lt;th&gt;match&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;45557690&lt;/td&gt;
&lt;td&gt;44375852&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;44349226&lt;/td&gt;
&lt;td&gt;45589067&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;45620618&lt;/td&gt;
&lt;td&gt;44714730&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Que es la forma que acepta el paquete igraph para generar el grafo que
va a vincular el id como en la imagen debajo, donde&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/nodes.png&#34; width=&#34;400px&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;6,9,10 y 4 ser√≠an un anuncio separado del resto, por ejemplo&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- --&gt;
&lt;pre&gt;&lt;code&gt;library(igraph)
g &amp;lt;- graph_from_data_frame(edges)
fc &amp;lt;- fastgreedy.community(as.undirected(g))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ahora fc es una lista en el que cada elemento es un vector de id&amp;rsquo;s que
corresponder√≠an al mismo inmueble para ver por ejemplo el grupo 3
podemos hacer:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;alqs %&amp;gt;% filter(id%in%  as.numeric(fc[[3]])) %&amp;gt;% View()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Los links asociados al grupo 3, entonces, son:&lt;/p&gt;
&lt;p&gt;[1]
&amp;ldquo;&lt;a href=&#34;https://www.zonaprop.com.ar/propiedades/arenales-y-callao-excelente-edificio-de-estilo-44714730.html&#34;&gt;https://www.zonaprop.com.ar/propiedades/arenales-y-callao-excelente-edificio-de-estilo-44714730.html&lt;/a&gt;&amp;rdquo;&lt;br&gt;
[2]
&amp;ldquo;&lt;a href=&#34;https://www.zonaprop.com.ar/propiedades/arenales-1700-43499494.html&#34;&gt;https://www.zonaprop.com.ar/propiedades/arenales-1700-43499494.html&lt;/a&gt;&amp;rdquo;
[3]
&amp;ldquo;&lt;a href=&#34;https://www.zonaprop.com.ar/propiedades/petit-hotel-arenales-y-callao-700-m-sup2--lote-propio-45138045.html&#34;&gt;https://www.zonaprop.com.ar/propiedades/petit-hotel-arenales-y-callao-700-m-sup2--lote-propio-45138045.html&lt;/a&gt;&amp;rdquo;
[4]
&amp;ldquo;&lt;a href=&#34;https://www.zonaprop.com.ar/propiedades/petit-hotel-arenales-y-callao-700-m-sup2--lote-propio-45564366.html&#34;&gt;https://www.zonaprop.com.ar/propiedades/petit-hotel-arenales-y-callao-700-m-sup2--lote-propio-45564366.html&lt;/a&gt;&amp;rdquo;
[5]
&amp;ldquo;&lt;a href=&#34;https://www.zonaprop.com.ar/propiedades/petit-hotel-arenales-y-callao-700-m-sup2--lote-propio-45564348.html&#34;&gt;https://www.zonaprop.com.ar/propiedades/petit-hotel-arenales-y-callao-700-m-sup2--lote-propio-45564348.html&lt;/a&gt;&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Al grupo 10:&lt;/p&gt;
&lt;p&gt;[1]
&amp;ldquo;&lt;a href=&#34;https://www.zonaprop.com.ar/propiedades/piso-pueyrredon-y-guido-191-m-sup2--una-o-dos-44047718.html&#34;&gt;https://www.zonaprop.com.ar/propiedades/piso-pueyrredon-y-guido-191-m-sup2--una-o-dos-44047718.html&lt;/a&gt;&amp;rdquo;&lt;br&gt;
[2]
&amp;ldquo;&lt;a href=&#34;https://www.zonaprop.com.ar/propiedades/pueyrredon-y-guido-piso-191-m-sup2--1-o-2-cocheras-44748468.html&#34;&gt;https://www.zonaprop.com.ar/propiedades/pueyrredon-y-guido-piso-191-m-sup2--1-o-2-cocheras-44748468.html&lt;/a&gt;&amp;rdquo;
[3]
&amp;ldquo;&lt;a href=&#34;https://www.zonaprop.com.ar/propiedades/piso-pueyrredon-y-guido-191-m-sup2--una-o-dos-45455991.html&#34;&gt;https://www.zonaprop.com.ar/propiedades/piso-pueyrredon-y-guido-191-m-sup2--una-o-dos-45455991.html&lt;/a&gt;&amp;rdquo;&lt;br&gt;
[4]
&amp;ldquo;&lt;a href=&#34;https://www.zonaprop.com.ar/propiedades/pueyrredon-2400-45078667.html&#34;&gt;https://www.zonaprop.com.ar/propiedades/pueyrredon-2400-45078667.html&lt;/a&gt;&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Pero no todo es un √©xito, tambien existen grupos tales como el 1, en el
que hay m√°s de uno:&lt;/p&gt;
&lt;p&gt;[1]
&amp;ldquo;&lt;a href=&#34;https://www.zonaprop.com.ar/propiedades/en-alquiler-temporario-departamentos-tipo-lofts-de-47-40313161.html&#34;&gt;https://www.zonaprop.com.ar/propiedades/en-alquiler-temporario-departamentos-tipo-lofts-de-47-40313161.html&lt;/a&gt;&amp;rdquo;
[2]
&amp;ldquo;&lt;a href=&#34;https://www.zonaprop.com.ar/propiedades/departamentos-en-alquiler-temporario-posadas-1300-40075639.html&#34;&gt;https://www.zonaprop.com.ar/propiedades/departamentos-en-alquiler-temporario-posadas-1300-40075639.html&lt;/a&gt;&amp;rdquo;&lt;br&gt;
[3]
&amp;ldquo;&lt;a href=&#34;https://www.zonaprop.com.ar/propiedades/alquiler-loft-m-sup2--47-posadas-1323-recoleta-amobl-y-41937518.html&#34;&gt;https://www.zonaprop.com.ar/propiedades/alquiler-loft-m-sup2--47-posadas-1323-recoleta-amobl-y-41937518.html&lt;/a&gt;&amp;rdquo;
[4]
&amp;ldquo;&lt;a href=&#34;https://www.zonaprop.com.ar/propiedades/gran-oport-recoleta-1-amb-47-m-sup2--piso-alto-en-41324130.html&#34;&gt;https://www.zonaprop.com.ar/propiedades/gran-oport-recoleta-1-amb-47-m-sup2--piso-alto-en-41324130.html&lt;/a&gt;&amp;rdquo;&lt;br&gt;
[5]
&amp;ldquo;&lt;a href=&#34;https://www.zonaprop.com.ar/propiedades/venta-1amb-al-frente-m-sup2--47-balcon-vista-a-los-41324195.html&#34;&gt;https://www.zonaprop.com.ar/propiedades/venta-1amb-al-frente-m-sup2--47-balcon-vista-a-los-41324195.html&lt;/a&gt;&amp;rdquo;&lt;br&gt;
[6]
&amp;ldquo;&lt;a href=&#34;https://www.zonaprop.com.ar/propiedades/venta-gran-oport-posadas-1323-1-amb-m-sup2--47-balcon-41163069.html&#34;&gt;https://www.zonaprop.com.ar/propiedades/venta-gran-oport-posadas-1323-1-amb-m-sup2--47-balcon-41163069.html&lt;/a&gt;&amp;rdquo;
[7]
&amp;ldquo;&lt;a href=&#34;https://www.zonaprop.com.ar/propiedades/departamento-tipo-lofts-m-sup2--47-amoblados-y-41242674.html&#34;&gt;https://www.zonaprop.com.ar/propiedades/departamento-tipo-lofts-m-sup2--47-amoblados-y-41242674.html&lt;/a&gt;&amp;rdquo;&lt;br&gt;
[8]
&amp;ldquo;&lt;a href=&#34;https://www.zonaprop.com.ar/propiedades/posadas-1323-edificio-alquiler-temporal-departamentos-41683158.html&#34;&gt;https://www.zonaprop.com.ar/propiedades/posadas-1323-edificio-alquiler-temporal-departamentos-41683158.html&lt;/a&gt;&amp;rdquo;
[9]
&amp;ldquo;&lt;a href=&#34;https://www.zonaprop.com.ar/propiedades/loft-al-frente.-amueblado-y-decoracion-de-diseno-42984563.html&#34;&gt;https://www.zonaprop.com.ar/propiedades/loft-al-frente.-amueblado-y-decoracion-de-diseno-42984563.html&lt;/a&gt;&amp;rdquo;&lt;br&gt;
[10]
&amp;ldquo;&lt;a href=&#34;https://www.zonaprop.com.ar/propiedades/posadas-1323-alquiler-depto-amobl.-y-equip-lofts-41775461.html&#34;&gt;https://www.zonaprop.com.ar/propiedades/posadas-1323-alquiler-depto-amobl.-y-equip-lofts-41775461.html&lt;/a&gt;&amp;rdquo;&lt;br&gt;
[11]
&amp;ldquo;&lt;a href=&#34;https://www.zonaprop.com.ar/propiedades/venta-y-alquiler-temporal-apartments-amoblados-41242680.html&#34;&gt;https://www.zonaprop.com.ar/propiedades/venta-y-alquiler-temporal-apartments-amoblados-41242680.html&lt;/a&gt;&amp;rdquo;&lt;br&gt;
[12]
&amp;ldquo;&lt;a href=&#34;https://www.zonaprop.com.ar/propiedades/venta-loft-m-sup2--47-balcon-al-frente.-o-en-alquiler-40116759.html&#34;&gt;https://www.zonaprop.com.ar/propiedades/venta-loft-m-sup2--47-balcon-al-frente.-o-en-alquiler-40116759.html&lt;/a&gt;&amp;rdquo;
[13]
&amp;ldquo;&lt;a href=&#34;https://www.zonaprop.com.ar/propiedades/posadas-1323-lofts-m-sup2--47-amobl-y-equip-confort-41768916.html&#34;&gt;https://www.zonaprop.com.ar/propiedades/posadas-1323-lofts-m-sup2--47-amobl-y-equip-confort-41768916.html&lt;/a&gt;&amp;rdquo;&lt;br&gt;
[14]
&amp;ldquo;&lt;a href=&#34;https://www.zonaprop.com.ar/propiedades/posadas-1323-apart-hotel-departamento-41682584.html&#34;&gt;https://www.zonaprop.com.ar/propiedades/posadas-1323-apart-hotel-departamento-41682584.html&lt;/a&gt;&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Pero en todo caso, esto efectivamente detecta gran parte de los
duplicados y puede asistir a que un ser humano genere la identificaci√≥n
de duplicados.&lt;/p&gt;
&lt;p&gt;Esto es un ejemplo de aprendizaje no-supervisado, pero si este analisis
se llevara a fondo obtendr√≠amos un set de datos de duplicaciones
etiquetadas, lo cual podr√≠a ser la base para el analisis con
procedimientos de analisis supervisados, y as√≠ encontrar patrones de que
causa la duplicaciones; lo cual mejorar√≠a el proceso de identificaci√≥n
de duplicados y podr√≠a usarse tambi√©n para optimizar los criterios
subjetivos que utilic√© mas arriba.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title></title>
      <link>/post/mardel_realstate/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/post/mardel_realstate/</guid>
      <description>&lt;h1 id=&#34;analysis-of-supply-and-evolution-of-the-real-state-market&#34;&gt;ANALYSIS OF SUPPLY AND EVOLUTION OF THE REAL STATE MARKET&lt;/h1&gt;
&lt;p&gt;The real state market is composed of a series of goods and sevices that
are heterogeneous in their characteristics and in their localization&lt;/p&gt;
&lt;p&gt;The features of each of the housing units in supply are, together, the
features of the market in general in a given timeframe&lt;/p&gt;
&lt;p&gt;Usually, what is obvserved is the supply stock and it is assumed that
the price is in equilibrium, in this sense, the supply is fixing a price
which will allow them to sell or rent at a price in the least amount of
time. Nevertheless, the flux of actual sales is not observable in this
sample, but it might be yet possible to determine by analysing the
changes in supply over time&lt;/p&gt;
&lt;p&gt;The scrapping methods takes the data monthly in order to get the
necessary data to perform such analysis.&lt;/p&gt;
&lt;p&gt;In this presentation, we&amp;rsquo;ll give a view of the supply. Leaving the
demand analysis for future oportunity&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lucasenrich.netlify.com/en/post/mardel_realstate/&#34;&gt;Read more &lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;study-of-supply&#34;&gt;Study of supply&lt;/h2&gt;
&lt;p&gt;The total amount of registers we have for the third trimester of 2019 in
our scrapping, once deleted repeated adds, is roughly 25675; of which
15562 are apartments and 5489 to houses.&lt;/p&gt;
&lt;p&gt;The next table is a summary of total and average squared meters, and
their values in US Dollars for Mar del Plata&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;references&lt;/strong&gt; Departamento = Apartment Casa = House PH = Horizontal
Property, a building with housing units much bigger that apartments but
has less than 3 floors Terreno = Land Local Comercial = Comerce shop
Local Comercial = Comerce office Garage = Garage Fondo de Comercio =
On-going business in sale Bodega-Galpon = shed (as big as a block
usually) Edificio = Building&lt;/p&gt;
&lt;table&gt;
&lt;caption&gt;Features of Sales dataset&lt;/caption&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Tipo&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Cantidad&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Precio_M2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Tama√±o&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Precio&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Departamento&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;15562&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2066&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;70&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;138747&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Casa&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5489&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;811&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;434&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;245960&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;PH&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1645&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1207&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;101&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;99352&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Terrenos&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1451&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;743&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;700&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;316334&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Local comercial&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;659&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1751&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;208&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;197579&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Oficina comercial&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;287&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1569&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;98&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;125887&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Garage&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;245&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;912&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1932&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;803429&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Fondo de Comercio&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;132&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1221&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;968&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1340016&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Bodega-Galp√≥n&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;99&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;611&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;875&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;336943&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Edificio&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;51&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1737&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;759&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;887350&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;From this table it came out that 82.16% of the supply is composed by
Departamento (60.74%) y Casa (21.42%) and that the apartments have the
highest prices by squared meter and the least change in supply&lt;/p&gt;
&lt;p&gt;Likewise the data reveal the variation in quantities, prices and sizes
of each type of housing unit&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/unnamed-chunk-3-1.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In this case we can see, for example, that, for apartments, the rise in
size (total squared meters) causes that, even though the total price
risses, the price by squared meters falls. The oposite occurs for the
PH&amp;rsquo;s&lt;/p&gt;
&lt;p&gt;The dataset also provides housing units that have activaly reduce it&amp;rsquo;s
prices in the last three months&lt;/p&gt;
&lt;table&gt;
&lt;caption&gt;Bajaron de Precio&lt;/caption&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Tipo&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Cantidad&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Baj√≥&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Precio_M2&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;var Precio m2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Tama√±o&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;var Tama√±o&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Precio&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;var Precio&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Departamento&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;207&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;8.63%&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1891&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-13.51%&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;54&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-33.65%&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;100875&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-35.72%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;PH&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;9.80%&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1173&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;12.05%&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;81&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-50.80%&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;91780&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-27.27%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;In the table we can see that the average price of apartments drop 8.63%,
meanwhile the prices of the PHs dropped even more, an average of 9.8%.&lt;/p&gt;
&lt;p&gt;The housing units that lowered the price also present a series of
features we can exam.&lt;/p&gt;
&lt;p&gt;The prices for squared meter that lowered the price are 13.5% cheaper
than the overall average, meaning that those which lower the price were
already cheaper than the overall sample. The same for sizes&lt;/p&gt;
&lt;p&gt;The PH&amp;rsquo;s have a peculiar feature. Even though, those which lowered the
price are smaller than the general sample, the price by squared meter is
higher. This is because the difference between the average size si
higher than the difference between the price of the housing unit&lt;/p&gt;
&lt;h2 id=&#34;real-state-brokers&#34;&gt;Real State brokers&lt;/h2&gt;
&lt;p&gt;The dataset provides as well, the real state broker since november 2019.
This allows us to evaluate better who is offering.&lt;/p&gt;
&lt;p&gt;To begin with, we can see that the majority of the brokers have a few
publications, 77% have less than 22 in this trimester. But there is also
brokers with a lot of publications; 1% of the brokers have between 276
and 419 publications&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/unnamed-chunk-6-1.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This data can also be used to track the market-share of each broker, and
analyse the evolution&lt;/p&gt;
&lt;h2 id=&#34;zones-of-supply-density&#34;&gt;Zones of Supply Density&lt;/h2&gt;
&lt;p&gt;The data is geolocated in 97%, which permits us to map it and visualize
the density of the real state supply. As expected, the major density are
near the center of town, near the bus terminal and near the cost; given
that Mar del Plata is a major tourist center&lt;/p&gt;
&lt;iframe seamless src=&#34;/img/densidad.html&#34; width=&#34;100%&#34; height=&#34;500&#34;&gt;&lt;/iframe&gt;
&lt;p&gt;A further anlysis of each zone can be made, so we can describe them&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/unnamed-chunk-8-1.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Overall, how is the supply distributed in each zone?&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/unnamed-chunk-9-1.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Esto nos dice que si bien la zona 6 ocupa el 10% de los m¬≤ ofrecidos,
constituye el 26% de las publicaciones. Y, conjuntamente con la zona 5,
son el 25% de los m¬≤ ofrecidos, pero superan el 52% del total de
publicaciones. This tell us that, even though zone 6 occupies 10% the m¬≤
offered, is 26% of the publications. And, toghether with zone 5, they
are more than 52% of the publications&lt;/p&gt;
&lt;p&gt;The variables than will be described for each zone are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Type of housing unit&lt;/li&gt;
&lt;li&gt;Size in squared meters&lt;/li&gt;
&lt;li&gt;Price by squared meter&lt;/li&gt;
&lt;li&gt;Total price&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;type&#34;&gt;Type&lt;/h3&gt;
&lt;p&gt;Below, we can see that the zone of least density (zone 0), the market is
composed mainly with land and houses. And as we advance to the zone of
major density (zone 6) the composition of the supply varies. In the
first place, the land are no longer offered, the apartments takes over
as the main type and in the center of town also appears comercial shops
and garages&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/unnamed-chunk-10-1.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This is exactly what one would expect, if the housing unit is smaller,
more units fit in a given space&lt;/p&gt;
&lt;h3 id=&#34;sizes&#34;&gt;Sizes&lt;/h3&gt;
&lt;p&gt;The sizes of each unit play a fundamental role in the geographical
concentration of the supply&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/unnamed-chunk-11-1.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As we saw in the &amp;ldquo;Type&amp;rdquo; section, we can quantify how the types which are
traditionaly the largest (houses, land) affect the concentration&lt;/p&gt;
&lt;h3 id=&#34;prices&#34;&gt;Prices&lt;/h3&gt;
&lt;p&gt;The prices in each area are more homogeneous than the sizes or any other
variable previously analyse. There is still a tendency that more supply
means less prices. For example, the least average price is in zone 6&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/unnamed-chunk-12-2.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This information, doesn&amp;rsquo;t reflect how the prices varies in each zone.
Prices in zone 6 may be the least, in average, but this prices hide a
major variabilty. Prices in zone 6 have 50% variation than in zone 0.
Meaning that, even though the prices are lower, in average, there are a
lot with higher prices, and with lower prices. And in zones where houses
are the main unit, the prices are more steady&lt;/p&gt;
&lt;h3 id=&#34;price-by-squared-meter&#34;&gt;Price by squared meter&lt;/h3&gt;
&lt;p&gt;This a sort of conclution of the two previous parts. We saw that the
units gets larger in less concentrated areas, and the total prices
doesn&amp;rsquo;t change that much. This means that the prices by squared meter
will be higher there where there is a major supply concentration&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/unnamed-chunk-13-1.png&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;as-price-zones&#34;&gt;As price zones&amp;hellip;&lt;/h3&gt;
&lt;p&gt;The same methology can be used to extract different zones, Prices,
number of rooms, etc which can be made ad hoc&lt;/p&gt;
&lt;iframe seamless src=&#34;/img/pm2_d.html&#34; width=&#34;100%&#34; height=&#34;500&#34;&gt;&lt;/iframe&gt;
&lt;p&gt;Some of the alternative maps can be seen in: 
&lt;a href=&#34;https://lucariel.shinyapps.io/mapa_inmobiliario/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;mapa
interactivo&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title></title>
      <link>/post/paso2019/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/post/paso2019/</guid>
      <description>&lt;h1 id=&#34;twitter-y-las-paso&#34;&gt;Twitter y las Paso&lt;/h1&gt;
&lt;p&gt;Esta fue mi primera aproximacion a minar datos de redes sociales,
amigarme con las APIs, y alg√∫n analysis rudimentario. Siguiendo
metodologias propuestas por otros.&lt;/p&gt;
&lt;p&gt;En principio vamos a comenzar con lo primero ¬øcomo hice para minar los
datos de twitter? Bueno para eso use tweepy (&lt;a href=&#34;http://www.tweepy.org/&#34;&gt;http://www.tweepy.org/&lt;/a&gt;)
Asique la primera parte va a estar en Python.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lucasenrich.netlify.com/post/PASO2019/&#34;&gt;Read more &lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Importando lo importante&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import tweepy
from tweepy.streaming import StreamListener
from tweepy import Stream
import time
from slistener import SListener
import os
import matplotlib.pyplot as plt
import json
import requests
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;por slistener es un script cortesia de
&lt;a href=&#34;https://github.com/alexhanna/hse-twitter/blob/master/bin/slistener.py&#34;&gt;https://github.com/alexhanna/hse-twitter/blob/master/bin/slistener.py&lt;/a&gt;
que permite crear un objeto que va a ser el &amp;ldquo;listener&amp;rdquo; o &amp;ldquo;escuchante&amp;rdquo; de
twitter. Para tomar los datos en tiempo real y poder ir guardandolos.&lt;/p&gt;
&lt;p&gt;Instanciando lo instanciable y setiando los paths donde van las cosas&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;auth = tweepy.OAuthHandler(&#39;zarazatoken&#39;, &#39;zarazatoken)
auth.set_access_token(&#39;zarazatoken&#39;, &#39;zarazatoken&#39;)
api = tweepy.API(auth)

datapath = os.path.join(os.getcwd(), &#39;data&#39;)
datafiles = os.listdir(datapath)

Y vamos a poder el escuchante a escuchar twitter

keywords_to_track = [&#39;EleccionesPASO2019&#39;, &#39;FrenteDeTodos&#39;,&#39;Frente Todos&#39;,
                     &#39;Juntos por el Cambio&#39;,&#39;Juntos Cambio&#39;,&#39;Elecciones&#39;,&#39;PASO&#39;,
                     &#39;YoTeVotoAlberto&#39;,&#39;NoVuelvenNuncaMas&#39;,
                    
&#39;ArgentinaVota&#39;,&#39;Macri&#39;,&#39;YoLoVoto&#39;,&#39;Fernandez&#39;,&#39;Kirchner&#39;]
stream.filter(track = keywords_to_track)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Los keywords a trackear se eligieron tomando los trending topic en
argentina referidos a las elecciones y algunos elegidos por mi, a mano&lt;/p&gt;
&lt;p&gt;stream.filter() lo que se encarga de hacer es ir tomando la muestra en
tiempo real de datos de twitter que se ajusten al filtro. Mientras corra
(es decir, mientras no se interrumpa) va a ir juntando los datos. Esto
lo empece a correr el domingo de las paso a las 7am y lo fren√© el mismo
d√≠a a las 17hs.&lt;/p&gt;
&lt;p&gt;La siguiente parte me fue bastante mas dificil de lo que habia
anticipado, porque estas muestras se guardan en formato &amp;ldquo;.json&amp;rdquo; lo cual
tenia que convertir a &amp;ldquo;.csv&amp;rdquo; para poder trabajar mejor&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import pandas as pd
import numpy as np
tweets = []
with open(os.path.join(datapath,datafiles[1]), &#39;r&#39;,encoding=&#39;utf-8&#39;, errors=&#39;ignore&#39;) as t:
    tw_json = t.read().split(&#39;\n&#39;)
    for tw in tw_json:
        #print(tw)
        #print(&#39;\t\t&#39;)
        try:
            tweet_obj = json.loads(tw)
        except:
            pass
        if &#39;extended_tweet&#39;in tweet_obj:
            tweet_obj[&#39;extended_tweet-text&#39;] =  tweet_obj[&#39;extended_tweet&#39;][&#39;full_text&#39;]
            if tw != &#39;&#39;:
                tweets.append(tw)
        
pd.DataFrame(tweets)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;¬°Ahora si! Ya tenemos bonito el data_frame en pandas para guardarlo y
seguir desde all√≠&lt;/p&gt;
&lt;p&gt;La siguiente tarea seria el topic extraction, pero la realidad es que
cuando lo hice no llegue a ningun lado, porque, obviamente y como es de
esperar, estaba todo referido a as elecciones. Lo que si termine
haciendo fue filtrar el dataset que me quedo por las keywords que
nombrar a los dos principales candidatos&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{&#39;YoVotoMM&#39;,&#39;juntosporelcambio&#39;, &#39;votomm&#39;,&#39;NoVuelvenNuncaMas&#39;, &#39;yolovoto&#39;,&#39;Macri&#39;} ## Quedar√≥n 6,320 registros

{&#39;FrenteDeTodos&#39;,&#39;futurocontodos&#39;,&#39;YoTeVotoAlberto&#39;,&#39;FernandezFernandez&#39;,&#39;CFK,&#39;cristina kirchner&#39;&#39;Alberto Fernandez&#39;} ## Quedar√≥n 5,554 registros
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ahora bien, ¬øde quien se hablaba mas en twitter?&lt;/p&gt;
&lt;p&gt;Primero al dataframe de cada topic se agrega la variable
correspondiente, se generan las dummies y luego se saca el promedio por
hora, lo que resulta en la proporcion de tuits de cada uno&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;macri[&#39;p&#39;] = &#39;MM&#39;
frente_de_todos[&#39;p&#39;] = &#39;FF&#39;

df1 = pd.concat([macri, frente_de_todos])

df2 = pd.get_dummies(df1.p)


mean_mm = df2[&#39;MM&#39;].resample(&#39;1 h&#39;).mean()
mean_ff = df2[&#39;FF&#39;].resample(&#39;1 h&#39;).mean()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Sacando el plot:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/plotpaso1.jpeg&#34; width=&#34;30%&#34; style=&#34;float:center; padding:0% 35%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Se ve que salvo a la ma√±ana y bien entrada la tarde, se hablo mas de
Macri.&lt;/p&gt;
&lt;p&gt;Bueno, habiendo hecho la primera parte en Python, es hora de continuar
con la parte de sentiment analysis de los tuits de las PASO. Esta vez,
en R. Vamos a empezar por las bibliotecas que necesitamos:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;library(tidyverse)
library(tidytext)
library(stopwords)
library(syuzhet)
library(stopwords)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Luego traemos los datos:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;paso&amp;lt;-read_csv(&#39;paso.csv&#39;)
paso&amp;lt;-paso[colnames(paso)!=&amp;quot;X1&amp;quot;]
paso_unique&amp;lt;-unique(paso$`extended_tweet-full_text`)
paso_unique2&amp;lt;-as_tibble(paso_unique)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;El unique() nos sirve para filtrar tuits duplicados. Que pueden ocurrir
por que un usuario cit√≥ a otro.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;length(paso$`extended_tweet-full_text`)
 
#Quedan 44423 registros


length(unique(paso$`extended_tweet-full_text`)) 
#Quedan 43996 registros
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Vamos a tokenizar las palabras:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tweet_token&amp;lt;-paso_unique2%&amp;gt;%
  unnest_tokens(word, txt)


tweet_token&amp;lt;-tweet_token%&amp;gt;%
  count(word, sort = T)%&amp;gt;%
  filter(!word%in% stopwords(&#39;es&#39;))%&amp;gt;%
  filter(!word%in% stopwords(&#39;en&#39;))%&amp;gt;%
  filter(str_detect(word, &amp;quot;^[a-zA-z]|^#|^@&amp;quot;))%&amp;gt;%
  ungroup()%&amp;gt;%
  arrange(desc(n))%&amp;gt;%
  mutate(w = word,
         freq = n)%&amp;gt;%
  select(w, freq)

## Resultado

   w                   freq
   &amp;lt;chr&amp;gt;              &amp;lt;int&amp;gt;
 1 t.co               18839
 2 https              18834
 3 paso               16293
 4 elecciones          8401
 5 macri               7982
 6 si                  5853
 7 eleccionespaso2019  5498
 8 votar               4950
 9 q                   4318
10 hoy                 3304
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Esto no es muuy bueno, hay tokens que hay que sacar.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tweet_token_2&amp;lt;-tweet_token%&amp;gt;%filter(w!=&#39;t.co&#39;)%&amp;gt;%filter(w!=&#39;https&#39;)%&amp;gt;%
  filter(w!=&#39;q&#39;)%&amp;gt;%filter(w!=&#39;to&#39;)%&amp;gt;%filter(w!=&#39;si&#39;)%&amp;gt;%filter(w!=&#39;and&#39;)%&amp;gt;%
  filter(w!=&#39;rt&#39;)

   w                    freq
   &amp;lt;chr&amp;gt;               &amp;lt;int&amp;gt;
 1 paso                16293
 2 elecciones           8401
 3 macri                7982
 4 eleccionespaso2019   5498
 5 votar                4950
 6 hoy                  3304
 7 argentinavota        3043
 8 eleccionesargentina  2878
 9 voto                 2588
10 trump                2409
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ahora si, mira que loco lo de Trump. Igual esto se ve mucho mejor con un
gr√°fico, adem√°s, no filtre todavia los stopwords y no filtre por tuits
en espa√±ol, asique probablemente sean tuits colados de otro tema&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tweet_token_2 [ 1 : 25 , ] %&amp;gt;%
  mutate ( w = forcats :: fct_inorder ( w ) ) %&amp;gt;%
  ggplot ( aes ( x = w , y = freq ) ) +
  geom_segment ( aes ( x = w , xend = w , y = 0 , yend = freq ) , color= &amp;quot;grey&amp;quot; )+
  geom_point(size = 3, color = &amp;quot;#009A44&amp;quot;)+
  coord_flip()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/plotpaso2.jpeg&#34; width=&#34;30%&#34; style=&#34;float:center; padding:0% 35%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Bueno, el termino &amp;ldquo;paso&amp;rdquo; es evidentemente el mas frecuente, lo cual es
mas que esperable. Luego, nos quedaria ver como se sentia la gente
respecto a esto. Para esto se uso la libreria syuzhet&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;base_emocion&amp;lt;-get_nrc_sentiment(unlist(paso_unique2))
base_emocion &amp;lt;- data.frame(t(base_emocion))
base_emocion &amp;lt;- data.frame ( rowMeans ( base_emocion ) )
names ( base_emocion ) [ 1 ] &amp;lt;- &amp;quot;Proporcion&amp;quot;
base_emocion &amp;lt;- cbind ( &#39;Sentimiento&#39; = rownames ( base_emocion ) , base_emocion )

base_emocion%&amp;gt;%
  ggplot()+geom_bar(aes(x = Sentimiento, y = Proporcion), stat = &#39;identity&#39;, fill = &#39;green&#39;, alpha = 0.8)+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Esta es la parte mas relevante que tome de Hernan, la diferencia que
tome, fue que √©l tomo la suma de cada una de los casos de cada
sentimiento, y yo la proporcion. Creo que eso puede reflejar de otra
forma cual es la emocion predominante en cada caso:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/plotpaso3.jpeg&#34; width=&#34;30%&#34; style=&#34;float:center; padding:0% 35%&#34; /&gt;
En este caso general, se ve que entre &amp;ldquo;positivo&amp;rdquo; y &amp;ldquo;negativo&amp;rdquo; son los
predominantes, seguidos por &amp;ldquo;confianza&amp;rdquo; y &amp;ldquo;enojo&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Esta misma metodologia se puede usar para los dos datasets separados
para cada topic pre-seleccionado, los referidos al frente de todos y a
juntos por el cambio&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/plotpaso4.jpeg&#34; width=&#34;30%&#34; style=&#34;float:center; padding:0% 35%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/plotpaso5.jpeg&#34; width=&#34;30%&#34; style=&#34;float:center; padding:0% 35%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Todos se quejan, pero de Cristina hablan todos. Igual hay que considerar
que de este conteo, se filtraron los nombres y apellidos de los
candidatos a la presidencia ya que es lo que se uso de filtro.&lt;/p&gt;
&lt;p&gt;¬øComo se sienten?
&lt;img src=&#34;/img/plotpaso6.jpeg&#34; width=&#34;30%&#34; style=&#34;float:center; padding:0% 35%&#34; /&gt;
&lt;img src=&#34;/img/plotpaso7.jpeg&#34; width=&#34;30%&#34; style=&#34;float:center; padding:0% 35%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Un poco de esto confirma no solo los resultado de la eleccion sino
tambien la lectura del voto &amp;ldquo;enojo&amp;rdquo;. Porque los sentimientos asociados a
cambiemos tienen mayor participacion de enojo y sentimientos negativos.
Mientras que los asociados al frente de todos tiene mucha mayor
participacion los tuits positivos.&lt;/p&gt;
&lt;p&gt;Un bonus track de python nada mas (esbozo de network analysis) ¬øA quien
se le contestaba mas para cada grupo?&lt;/p&gt;
&lt;p&gt;Las libreras de python son las mismas que el post anterior solo con la
adicional de Networkx que permite hacer el analisis de redes.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import networkx as nx

frente_de_todos = pd.read_csv(&#39;frente_de_todos.csv&#39;)
cambiemos = pd.read_csv(&#39;cambiemos.csv&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Una vez leidos, filtramos los tuits que &amp;ldquo;son respuesta a&amp;rdquo;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cambiemos_nx = cambiemos_nx[-cambiemos_nx[&#39;in_reply_to_screen_name&#39;].isnull()]
cambiemos_nx[&#39;in_reply_to_screen_name&#39;]
frente_de_todos_nx = frente_de_todos_nx[-frente_de_todos_nx[&#39;in_reply_to_screen_name&#39;].isnull()]
frente_de_todos_nx[&#39;in_reply_to_screen_name&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Se generan las redes de c/u; esto genera que cada usuario sea un nodo y
que la relacion entre los usuarios se d√°, en este caso particular, si
responden a un tuit es decir: si yo te respondo un tuit, nosotros dos
generamos una red que tiene mi nombre (mi usuario) como nodo de inicio y
tu nodo (tu usuario) como nodo destino. Cada objeto, entonces, va a
tener tantas salidas como respuestas haya hecho y tantas entradas como
respuestas haya recibido:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;G_reply_c = nx.from_pandas_edgelist(
    cambiemos_nx,
    source = &#39;user-screen_name&#39;,
    target = &#39;in_reply_to_screen_name&#39;,
    create_using = nx.DiGraph())

G_reply_f = nx.from_pandas_edgelist(
    frente_de_todos_nx,
    source = &#39;user-screen_name&#39;,
    target = &#39;in_reply_to_screen_name&#39;,
    create_using = nx.DiGraph())
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Y vemos la centralidad de cada tuitero (&amp;ldquo;in-degree-centrality&amp;rdquo;), que en
realidad seria la respuesta a la pregunta &amp;ldquo;¬øA quien se le esta
contestando m√°s?&amp;rdquo;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#Para Frente de Todos - ¬øa quien se le contesta cuando se habla de estse #tema?

G_reply_f = nx.from_pandas_edgelist(
    frente_de_todos_nx,
    source = &#39;user-screen_name&#39;,
    target = &#39;in_reply_to_screen_name&#39;,
    create_using = nx.DiGraph())


bc = nx.in_degree_centrality(G_reply_f)
indg = pd.DataFrame(list(bc.items()), columns =[&amp;quot;Name&amp;quot;,&#39;Cent&#39;])
indg.sort_values(&#39;Cent&#39;, ascending=False)
Name    Cent
153 alferdez        0.018328
18  ierrejon        0.017182
137 LotusHerbals    0.017182
115 todonoticias    0.016037
113 fllorenteantoni 0.013746
746 AlbertoRavell   0.010309
159 FernandezAnibal 0.010309
147 LeonelFernandez 0.006873
236 mirthalegrand   0.006873
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Y en el caso del Juntos Por el Cambio&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;G_reply_c = nx.from_pandas_edgelist(
    cambiemos_nx,
    source = &#39;user-screen_name&#39;,
    target = &#39;in_reply_to_screen_name&#39;,
    create_using = nx.DiGraph())

bc = nx.in_degree_centrality(G_reply_c)
indg = pd.DataFrame(list(bc.items()), columns =[&amp;quot;Name&amp;quot;,&#39;Cent&#39;])
indg.sort_values(&#39;Cent&#39;, ascending=False)

Name    Cent
36  mauriciomacri   0.021858
148 fllorenteantoni 0.012610
131 gabicerru       0.011349
84  juansolervalls  0.008827
119 EsmeraldaMitre  0.007566
3   todonoticias    0.005885
99  CamiSolovitas   0.004624
17  Alfredo5019     0.004624
23  SantoroLeandro  0.004203 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;FIN! Gracias por leer hasta ac√°! Si tienen alguna recomendacion para
tener en cuenta futuros analisis se los agradece!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title></title>
      <link>/post/review_rating/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/post/review_rating/</guid>
      <description>&lt;h1 id=&#34;review-rating&#34;&gt;Review Rating&lt;/h1&gt;
&lt;p&gt;¬øC√≥mo generar un puntaje n√∫merico en base a un texto?&lt;/p&gt;
&lt;p&gt;Mucho de lo expuesto es en realidad distintas formas de pensar el
problema y quedarse con la mejor soluci√≥n.&lt;/p&gt;
&lt;p&gt;Paseo por Doc2Vec, Regresiones lineales, randomForests y redes convolutivas
con GloVe&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lucasenrich.netlify.com/post/review_rating/&#34;&gt;Read more &lt;/a&gt;&lt;/p&gt;
&lt;p&gt;En principio, lo que se va a ver es las calificaciones haciendo uso de
Doc2Vec para convertir el texto en un vector numerico y poder, con esos
vectores numericos como input, realizar la predicci√≥n de cual ser√≠a la
calificaci√≥n que hubiera tenido seg√∫n el texto. Haciendo uso de
algortimos de aprendizaje supervisado.&lt;/p&gt;
&lt;p&gt;Por otro lado, dado que los datos no son tantos, lo que perjudica la
construcci√≥n del vector numerico a partir de los textos, se har√° uso de
un &amp;ldquo;word embedding&amp;rdquo; ya entrenado y posteriormente se ver√° como mejora el
poder predictivo.&lt;/p&gt;
&lt;h3 id=&#34;los-datos-y-la-limpieza&#34;&gt;Los datos y la limpieza&lt;/h3&gt;
&lt;p&gt;Para empezar, veamos como se ven los datos:&lt;/p&gt;
&lt;table style=&#34;width:39%;&#34;&gt;
&lt;colgroup&gt;
&lt;col width=&#34;16%&#34; /&gt;
&lt;col width=&#34;22%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;review.rating&lt;/th&gt;
&lt;th&gt;review.text&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;Our experience at Rancho Valencia was absolutely perfect from beginning to end!!!! We felt special and very happy during our stayed. I would come back in a heart beat!!!&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;Amazing place. Everyone was extremely warm and welcoming. We&#39;ve stayed at some top notch places and this is definitely in our top 2. Great for a romantic getaway or take the kids along as we did. Had a couple stuffed animals waiting for our girls upon arrival. Can&#39;t wait to go back.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;We booked a 3 night stay at Rancho Valencia to play some tennis, since it is one of the highest rated tennis resorts in America. This place is really over the top from a luxury standpoint and overall experience. The villas are really perfect, the staff is great, attention to details (includes fresh squeezed orange juice each morning), restaurants, bar and room service amazing, and the tennis program was really impressive as well. We will want to come back here again.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;En lugar de importar todos los paquetes juntos, vamos a ir importando a
medida que vayamos necesitando.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import pandas as pd
cc = pd.read_csv(&#39;./hotel-reviews/Datafiniti_Hotel_Reviews.csv&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Vamos a seleccionar las columnas necesarias y cambiarle el nombre para
que sea mas facil luego seleccionarlas.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cc = cc[[&#39;reviews.title&#39;,&#39;reviews.text&#39;,&#39;reviews.rating&#39;]]
cc.columns = [&#39;titulo&#39;,&#39;comentarios&#39;,&#39;calificacion&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;El primer paso a la hora de trabajar con estos textos, es reducir a la
maxima expresi√≥n la cardinalidad del vocabulario. ¬øQue significa esto?
Si tenemos una gran cantidad de usos de un verbo, como por ejemplo,
&amp;ldquo;correr&amp;rdquo; en sus distintas conjugaciones, &amp;ldquo;corr√≠a&amp;rdquo;,&amp;ldquo;corriendo&amp;rdquo;,&amp;ldquo;corrian&amp;rdquo;
y queremos armar un listado de frecuencias de palabras, esto daria como
resultado que cada uno de esas palabras aparezca una sola vez; pero si
logramos que la referencia a la acci√≥n concreta de &amp;ldquo;correr&amp;rdquo; sume
independientemente de su conjugaci√≥n, reducir√≠amos la cardinalidad de
nuestro diccionario, eso es para lo que se usa la &lt;em&gt;lematizaci√≥n&lt;/em&gt;.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;Original&lt;/th&gt;
&lt;th&gt;Lemmatizacion&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;corrian&lt;/td&gt;
&lt;td&gt;correr&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;corriendo&lt;/td&gt;
&lt;td&gt;correr&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;corrio&lt;/td&gt;
&lt;td&gt;correr&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Luego, hay sustantivos y otras palabras que tienen la misma raiz y
dependiendo del sujeto, se puede reducir el tama√±o del diccionario
cortando de la raiz la palabra, lo que se conoce como &lt;em&gt;stemmizaci√≥n&lt;/em&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;Original&lt;/th&gt;
&lt;th&gt;Stemmizaci√≥n&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;ni√±a&lt;/td&gt;
&lt;td&gt;ni√±e&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;ni√±o&lt;/td&gt;
&lt;td&gt;ni√±e&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;ni√±e&lt;/td&gt;
&lt;td&gt;ni√±e&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;El proceso de lematizaci√≥n y stemizaci√≥n, en su conjunto, se puede
entender como normalizar el vocabulario y por lo tanto, una funci√≥n que
se encarge de hacer estas dos cosas, puede llamarse &lt;em&gt;normalize(text)&lt;/em&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def normalize(text):
    from nltk.stem import PorterStemmer
    from nltk.tokenize import word_tokenize
    import unidecode
    import spacy
    nlp = spacy.load(&#39;en_core_web_sm&#39;)
    porter = PorterStemmer()
    doc = nlp(text)
    lemmas = [unidecode.unidecode(tok.lemma_.lower()) for tok in doc if not tok.is_punct ]
    #En este caso, estoy eliminando palabras con menos de 3 letras y las negaciones, esto no es necesario estrictamente, y depende mucho del caso de aplicaci√≥n, a veces funciona, a veces no.
    lexical_tokens = [t.lower() for t in lemmas if (len(t) &amp;gt; 3 or t ==&amp;quot;no&amp;quot;) and t.isalpha()]
    lexical_tokens = [porter.stem(t) for t in lexical_tokens]
    return lexical_tokens
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Esta funcion tiene como input una frace y escupe objeto tipo list()
asique lo que har√© es aplicarla a cada texto y despues volverla a unir
para que cada fila tenga un texto y no un array&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;norm_token = []
for i in range(len(cc.comentarios)):
    try:
        a = normalize(cc.comentarios[i])
    except:
        a = &#39;&#39;
    norm_token.append(a)
norm_text = [&#39; &#39;.join(x) for x in norm_token]
cc[&#39;norm_text&#39;] = norm_text
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;doc2vec-generando-el-embedding-num√©rico&#34;&gt;Doc2Vec: Generando el embedding num√©rico&lt;/h3&gt;
&lt;p&gt;¬øPorque no tratar directo con los tokens? Por la sencilla raz√≥n hay un
paquete que permite aplicar Doc2Vec, asociando un texto a una clase,
&lt;em&gt;gensim&lt;/em&gt; nos va a venir bien para esto:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;from gensim.models.doc2vec import Doc2Vec, TaggedDocument
#Primera la separacion entre test y train
train, test = train_test_split(cc, test_size=0.2, random_state=42)

train_tagged = train.apply(
    lambda r: TaggedDocument(words=word_tokenize(r.norm_text), tags=[r.calificacion]), axis=1)
test_tagged = test.apply(
    lambda r: TaggedDocument(words=word_tokenize(r.norm_text), tags=[r.calificacion]), axis=1)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Una vez que tenemos los elementos de train y test, hay que entrenar el
Doc2Vec, para, as√≠ pasar el texto a un vector n√∫merico que pueda ser el
input del algoritmo de clasificaci√≥n&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;for epoch in range(30):

    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)
    model_dbow.alpha -= 0.002
    model_dbow.min_alpha = model_dbow.alpha
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Con el modelo Doc2Vec entrenado, podemos darle pasar los textos y
obtener el vector numerico deseado. Ahora bien, para facilitar la
implementaci√≥n del modelo despu√©s, generemos una funci√≥n con dos ouputs,
el vector numerico por un lado, y el rating asociado a ese vector
num√©rico&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def vec_for_learning(model, tagged_docs):
    sents = tagged_docs.values
    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])
    return targets, regressors
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ahora que tenemos la funci√≥n que nos genera el vector n√∫merico
terminamos con el proceso de preparaci√≥n de los datos. Es curioso notar
que siempre se dice que el 80% del trabajo consiste en la preparaci√≥n y
limpieza de datos, y el 20% el modelado. Hasta ahora se puede ver que no
es una distinci√≥n tan discreta, sino que es continua. ¬øA qu√© me refiero?
Bueno, para preparar los datos hizo falta algoritmos de embedding
(Doc2Vec). Y no es poco com√∫n que ocurran estas cosas.&lt;/p&gt;
&lt;p&gt;Ahora bien, volvamos a lo nuestro, es hora de correr los algoritmos de
regresi√≥n:&lt;/p&gt;
&lt;h3 id=&#34;regresi√≥n&#34;&gt;Regresi√≥n&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression

y_train, X_train = vec_for_learning(model_dbow, train_tagged)
y_test, X_test = vec_for_learning(model_dbow, test_tagged)

lr = LinearRegression()
lr.fit(X_train, y_train)
y_pred = lr.predict(X_test)

print(np.sqrt(mean_squared_error(y_test, y_pred))) #1.15
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Este resultado no me convence demasiado si consideramos al puntaje como
una regresi√≥n. El error cuadratico medio es del 1.15pts, para los que no
recuerdan, el error cuadratico medio toma la diferencia entre el valor
predecido y el valor real, lo eleva al cuadrado y de ello toma el
promedio. Les dejo un &lt;a href=&#34;https://www.youtube.com/watch?v=8wgy8Vopv3E&#34;&gt;video &lt;/a&gt; de mi canal de Youtube con la visualizaci√≥n
de lo que significa&lt;/p&gt;
&lt;h3 id=&#34;clasificaci√≥n&#34;&gt;Clasificaci√≥n&lt;/h3&gt;
&lt;p&gt;Otra forma de entender el problema es como uno de clasificaci√≥n. ¬øPero
como pasamos de un target continuo a uno discreto? Podr√≠amos pensar que
los puntajes de 4 √≥ 5 son &amp;ldquo;buenos&amp;rdquo;, y asignarles un 1, y los de menos de
4 son &amp;ldquo;malos&amp;rdquo;, y asignarles un 0, y nos quedamos con un problema de
clasificaci√≥n binaria.&lt;/p&gt;
&lt;p&gt;Adem√°s, con estas conceptualizaci√≥n, tenes que volver a correr el
embedding porque los &amp;ldquo;tags&amp;rdquo; no son ahora los puntajes del 1 al 5 sino
que son {1,0}&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cl = []
for i in cc.calificacion:
    if i &amp;lt;4:
        cl.append(0)
    else:
        cl.append(1)
cc.calificacion = cl

train, test = train_test_split(cc, test_size=0.2, random_state=42)

train_tagged = train.apply(
    lambda r: TaggedDocument(words=word_tokenize(r.norm_text), tags=[r.calificacion]), axis=1)
test_tagged = test.apply(
    lambda r: TaggedDocument(words=word_tokenize(r.norm_text), tags=[r.calificacion]), axis=1)
model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0)
model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])
for epoch in range(30):
    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)
    model_dbow.alpha -= 0.002
    model_dbow.min_alpha = model_dbow.alpha
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ahora si, sacamos los vectores del modelo Doc2Vec y lo fiteamos a un
randomForest clasificador:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;from sklearn.ensemble import RandomForestClassifier
y_train, X_train = vec_for_learning(model_dbow, train_tagged)
y_test, X_test = vec_for_learning(model_dbow, test_tagged)


rfr = RandomForestClassifier(n_estimators = 500, random_state = 42)
rfr.fit(X_train, y_train)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;¬øC√≥mo evaluamos esta clasificaci√≥n? Bueno, primero nos fijamos cuanto
coincide la predicci√≥n respecto al valor real, para eso se usa la matriz
de confusi√≥n&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;from sklearn.metrics import confusion_matrix
y_pred = rfr.predict(X_test)
tn, fp, fn, tp = confusion_matrix(y_test, y_pred, labels=[0,1]).ravel()


np.mean(y_test == y_pred)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nuestra precisi√≥n es del 72,4%, nada mal, solo un detalle. Si mandamos
un modelo que siempre diga &amp;ldquo;1&amp;rdquo;, tendremos una precisi√≥n equivalente a la
proporci√≥n de &amp;ldquo;1&amp;rdquo; en el set. Que en la base completa es de 72,8%. Es
decir, este modelo no mejor que decir que todas son igual a &amp;ldquo;1&amp;rdquo;.&lt;/p&gt;
&lt;h3 id=&#34;polaridad-como-m√©trica&#34;&gt;Polaridad como m√©trica&lt;/h3&gt;
&lt;p&gt;Otra alternativa puede ser extraer la polaridad del texto, herramienta
muy √∫til en los procesos de sentiment analysis. Y podr√≠amos pensar que,
cuan m√°s positivo sea la polaridad, estar√° asociado a un mejor puntaje&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;from textblob import TextBlob 
pls = []
sbj = []
for i in range(len(cc.comentarios)):
    try:
        senti = TextBlob(cc.comentarios[i]) 
        polarity = senti.sentiment
        pls.append(polarity[0])
        sbj.append(polarity[1])
    except:
        pls.append(0)
        sbj.append(0)
        

polscore = [int(x &amp;gt; 0) for x in pls] # Ac√° 0 es un valor arbitrario de corte, 
#un ejericio podr√≠a incluir la optimizaci√≥n de este valor como un hiperparametro. 
#La polaridad genera un indice de -1, 1. Siendo -1 cuan m√°s negativo es, y 1 cuan m√°s #positivo es, y polscore dice que aquellos que tienen valoracion positiva sean 1 y los dem√°s 0
np.mean(polscore == np.array(cc.calificacion))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Sirve esto? Y, esto esta dando un resultado de 78.55%, es, a mi
sorpresa, una mejora respecto al punto anterior. Aunque todav√≠a no es
satisfactorio.&lt;/p&gt;
&lt;p&gt;Evidentemente el score de polarizaci√≥n agrega informaci√≥n.&lt;/p&gt;
&lt;h3 id=&#34;redes-neuronales-y-glove&#34;&gt;Redes neuronales y GloVe&lt;/h3&gt;
&lt;p&gt;Global Vectors √≥ &lt;a href=&#34;https://nlp.stanford.edu/projects/glove/&#34;&gt;GloVe &lt;/a&gt; es una tecnica que, a diferencia de Doc2Vec, que
es un algortimo supervisado, es no-supervisado y obtiene embedings
n√∫mericos de palabras seg√∫n estadisticas de co-ocurrencia. De esta
manera puede encontrar analog√≠as tales como &amp;ldquo;los que var√≥n es a mujer,
rey es a reina&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;M√°s all√° las &lt;a href=&#34;https://towardsdatascience.com/gender-bias-word-embeddings-76d9806a0e17&#34;&gt;controversias &lt;/a&gt;,
es una herramienta bastante √∫til para muchos casos&lt;/p&gt;
&lt;p&gt;El objetivo de esta secci√≥n es ver como, haciendo uso de un modelo de
lenguage pre-existente, se puede usar el proceso de transfer-learning
para incorporar nuestros textos y sus calificaciones y adaptarlo a
nuestras necesidades.&lt;/p&gt;
&lt;p&gt;Esto es interesante e importante porque hay muchos modelos de lenguage
que han hecho uso de datasets enormes en hardwares mucho m√°s potentes
que los que podr√≠a pagar, que se puede aprovechar&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import os
import sys
import numpy as np
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras.utils import to_categorical
from keras.layers import Dense, Input, GlobalMaxPooling1D
from keras.layers import Conv1D, MaxPooling1D, Embedding
from keras.models import Model
from keras.initializers import Constant


BASE_DIR = os.getcwd()
GLOVE_DIR = os.path.join(BASE_DIR, &#39;glove.6B&#39;) #Este es el modelo pre-entrenado
TEXT_DATA_DIR = os.path.join(BASE_DIR, &#39;20_newsgroup&#39;)
MAX_SEQUENCE_LENGTH = 1000 #entrenar sobre oraciones de hasta estas palabras
MAX_NUM_WORDS = 20000 #tama√±o m√°ximo del vocabulario
EMBEDDING_DIM = 300 #dimensi√≥n del vector n√∫merico resultante
VALIDATION_SPLIT = 0.2

#Volvemos a cargar la informaci√≥n
import pandas as pd
cc = pd.read_csv(&#39;./hotel-reviews/Datafiniti_Hotel_Reviews.csv&#39;)
cc = cc[[&#39;reviews.title&#39;,&#39;reviews.text&#39;,&#39;reviews.rating&#39;]]
cc.columns = [&#39;titulo&#39;,&#39;comentarios&#39;,&#39;calificacion&#39;]

cl = []
for i in cc.calificacion:
    if i &amp;lt;4:
        cl.append(0)
    else:
        cl.append(1)
cc.calificacion=cl

#Preparaci√≥n de los datos
TEXT_DATA_DIR = cc.comentarios

embeddings_index = {}
with open(os.path.join(GLOVE_DIR, &#39;glove.6B.100d.txt&#39;)) as f:
    for line in f:
        word, coefs = line.split(maxsplit=1)
        coefs = np.fromstring(coefs, &#39;f&#39;, sep=&#39; &#39;)
        embeddings_index[word] = coefs

texts = [x for x  in cc.comentarios]  # listado de muestras de texto
labels_index = {1:1, 2:2, 3:3, 4:4, 5:5}  # diccionario mapeando los revies a los target
labels = [int(x) for x in cc.calificacion] # target

# Tokenizar las palabras
texts = np.array(texts)
tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)
tokenizer.fit_on_texts(texts)
sequences = tokenizer.texts_to_sequences(texts)
word_index = tokenizer.word_index


#Con las palabras  tokenizadas, se hace el padding, para que todos tengan la misma longitud, para eso se agrega 0 hasta que se llene
data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)

labels = to_categorical(np.asarray(labels))

indices = np.arange(data.shape[0])
np.random.shuffle(indices)
data = data[indices]
labels = labels[indices]
num_validation_samples = int(VALIDATION_SPLIT * data.shape[0])

x_train = data[:-num_validation_samples]
y_train = labels[:-num_validation_samples]
x_val = data[-num_validation_samples:]
y_val = labels[-num_validation_samples:]


num_words = min(MAX_NUM_WORDS, len(word_index) + 1)
embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))
for word, i in word_index.items():
    if i &amp;gt;= MAX_NUM_WORDS:
        continue
    embedding_vector = embeddings_index.get(word)
    if embedding_vector is not None:
        embedding_matrix[i] = embedding_vector

#Este es el proceso que genera los embeddings
embedding_layer = Embedding(num_words,
                            EMBEDDING_DIM,
                            embeddings_initializer=Constant(embedding_matrix),
                            input_length=MAX_SEQUENCE_LENGTH,
                            trainable=False)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok, hasta ahi la preparaci√≥n de los datos, es hora de entrenar una red
neuronal convolutiva con los embeddings realizados para obtener el
modelo que clasifique las reiews:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=&#39;int32&#39;)
embedded_sequences = embedding_layer(sequence_input)
x = Conv1D(128, 6, activation=&#39;relu&#39;)(embedded_sequences)
x = MaxPooling1D(5)(x)
x = Conv1D(128, 6, activation=&#39;relu&#39;)(x)
x = MaxPooling1D(6)(x)
x = Conv1D(128, 6, activation=&#39;relu&#39;)(x)
x = GlobalMaxPooling1D()(x)
x = Dense(128, activation=&#39;relu&#39;)(x)
preds = Dense(2, activation=&#39;softmax&#39;)(x)

model = Model(sequence_input, preds)
model.compile(loss=&#39;categorical_crossentropy&#39;,
              optimizer=&#39;rmsprop&#39;,
              metrics=[&#39;acc&#39;])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hay mucho c√≥digo repetido en este caso, pero eso es para simplicidad de
exposici√≥n, lo relevante a enteder es que as√≠ se define la capa
convolutiva, que esla que se repite:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;x = Conv1D(128, 6, activation=&#39;relu&#39;)(embedded_sequences)
x = MaxPooling1D(5)(x)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Y as√≠ la ultima capa, que como terminamos con las &amp;ldquo;buenas&amp;rdquo; y &amp;ldquo;malas&amp;rdquo;
reviews, tiene una funci√≥n de activaci√≥n binaria en el output&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;x = Dense(128, activation=&#39;relu&#39;)(x)
preds = Dense(2, activation=&#39;softmax&#39;)(x)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Una vez preparados los datos, y una vez definidas las capas de la red
neuronal se entrena:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;model.fit(x_train, y_train,
          batch_size=128,
          epochs=10,
          validation_data=(x_val, y_val))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Este fit, obtiene un accuracy que supera el 90%. Un gran paso adelante.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
