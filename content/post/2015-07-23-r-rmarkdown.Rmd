---
title: "Clustering con Estilo"
author: "Lucas Enrich"
categories: ["Clustering","Aprendizaje no supervisado","Non-supervised learning"]
tags: ["dbscan", "hdbscan", "PCA","umap","R"]
output: md_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE)
library(tidyverse)

```

##


_El problema_: Clusterizar diseños

¿Como hago para clasificar estilos de banners?

Con tantos adds dando vueltas en internet, sigue siendo, muchas veces, un proceso relativamente manual y poco estandarizado los diseños. Para eso existen diseñadores. 

Pero cuando ya tienen miles realizados, esta bueno mirar atrás e identificar patrones recurrentes. Saber lo que venimos haciendo sirve para mirar hacia adelante.

<!--more-->

```{r, out.width = "400px", echo = F}
knitr::include_graphics("/img/banner-example.png")
```


##
 
**Input data**

El problema tenia originalmente cientos de diseños, en este ejemplo, dado que tiene que ver con algoritmos de clusterización, se usaran algunos hechos ad hoc, por lo que el ejemplo es con tamaños reducidos y la clasificacion de imagenes, fuentes de texto y demás quedan afuera. Lo que queremos saber es si la ubicación de los elementos en la imagen sigue un patron en particular. 

Los datos venian de la siguiente forma:

```{r, out.width= "65%", out.extra='style="float:left; padding:20px"', echo = F}
knitr::include_graphics("/img/input_data.png")
```

Donde:

* <font size = 3> _y_ : Distancia desde arriba </font>

* <font size = 3> _x_ : Distancia desde la  izquierda </font>

* <font size = 3> _w_ : Ancho (width) </font>

* <font size = 3> _h_ : Alto (height) </font>

Si tenemos 50 ejemplos, con 3 elementos cada uno, y hay 4 variables por elemento, la forma del input es $50 \times 3 \times 4$, esto, a los algoritmos, no les gusta demasiado. Asique fue necesario achatar la base para obtener una base de datos de $50 \times 12$, para lo cual:

Primero se agarra cada uno (una base de $1\times 3 \times 4$) y se la transforma en una sola fila $1\times 12$ para lo cual se uso el código:

```{r, eval=F, echo=T, size='tiny'} 
library(tidyverse)
cols_used = c('element_top', 'element_left', 'element_width', 'element_height')
spread_file<-function(data, cols_used){
  cols_used_a = c('element_name',cols_used)
  y=data[cols_used]
  h = data[cols_used_a]
  z=c(1,1,1,1)
  for(i in 1:nrow(y)) {
    z = cbind(z,y[i,])
  }
  z = z[1,-1] 
  
  newcols <- c()
  for (i in  h['element_name']){
    newcols<-cbind(newcols,paste(i,cols_used[1], sep = '.'))
    newcols<-cbind(newcols,paste(i,cols_used[2], sep = '.'))
    newcols<-cbind(newcols,paste(i,cols_used[3], sep = '.'))
    newcols<-cbind(newcols,paste(i,cols_used[4], sep = '.'))
  }
  newcols2<-c()
  for(i in 1:nrow(newcols)) {
    for(j in 1:4){
      newcols2<-c(newcols2,newcols[i,j])
    }
  }
  colnames(z)<-newcols2
  n<-as_vector(data['id'])
  z['id']<-n[1]
  z
}


```

Lo que transforma cada elementos con la forma:

$$\begin{bmatrix} elem1 & y_1 & x_1 & w_1 & h_1 \\   elem2 & y_2 & x_2 & w_2 & h_2  \\   \vdots \\   elemk & y_2 & x_k & w_k & h_k \end{bmatrix}$$
a la forma:



$$\begin{bmatrix} 
   id.1 & elem.1.x & elem.1.y & elem.1.h & elem.1.w & ... & elem.k.w
\end{bmatrix}$$
Así se pueden apilar todos elementos de la muestra para quedar una sola base de datos con la forma:

$$\begin{bmatrix} id.1 & elem.1.x & elem.1.y & elem.1.h & elem.1.w & ... & elem.k.w \\ id.2 & elem.1.x & elem.1.y & elem.1.h & elem.1.w & ... & elem.k.w \\ \vdots \\ id.N & elem.1.x & elem.1.y & elem.1.h & elem.1.w & ... & elem.k.w \end{bmatrix}$$

 


*  <font size = 3> Reduccion de dimensionalidad  + Clustering  </font>

La forma más directa para realizar la tarea de clusterización es simplemente usando el paquete __dbscan__ y correrlo sobre nuestra base transformada. Pero no funcionó del todo. Asique lo siguiente fue reducir la dimensionalidad de los objetos, en este caso se uso el algoritmo UMAP y luego se hizo la clusterización.

PCA (componentes principales), es el algoritmo más popular para reducir la dimensionalidad. Luego esta t-SNE. 

En pocas palabras, UMAP fue la mejor opción porque utiliza un algoritmo rapido que preserva mejor la estructura global.

Y finalmente:

```{r, eval=F, echo=T, size='tiny'} 

library(umap)
library(dbscan)
umap_data<- umap(data)
cl <-hdbscan(x = umap_data, minPts = 3)

```

Pero también habia un tema de escala, quiza el diseño era parecido pero un banner era dos veces mas grande, por lo que el resultado no era adecuado.


<font size = 3> 
Surge la necesidad de transformar los datos

Opciones
</font>

* <font size = 2> Estandarizacion (z-score): Representa el numero de desvios estandar arriba o debajo del valor resultante. **Útil para variables normalmente distribuidas** </font>

* <font size = 2> Normalizacion (min-max scaler): Permite llevar los valores entre 0 y 1. **Útil para comparar variables de diferentes ordenes de magnitud** (Precio de una casa y los m2 que ocupa) 
</font>

```{r, out.width= "65%", out.extra='style="float:left; padding:20px"', echo = F}
knitr::include_graphics("/img/normaliz_data.png")
```



**¿Puedo usar estas transformaciones en estos datos?**


<font size = 4>

* No, como las variables describen dimensiones (alto y ancho), y posicion en el espacio
no le encontré mucho sentido a la estandarizacion ni la normalizacion.  




</font>



<font size = 4>

* ¿Que podría hacer? En lugar de ver las posiciones y dimensiones *absolutas*, ver las posiciones y dimensiones *relativas*, lo que voy a llamar "normalizacion geometrica"

```{r, eval=F, echo=T, size='tiny'} 
normalize_geometric<-function(df){
  df['total_area']<-max(df['element_height'])*max(df['element_width'])

  df['rel_area']<-df['element_height']*df['element_width']/df['total_area']
  
  df['orientation']<-df['element_height']/df['element_width']
  
  df['element_top_relative']<-df['element_top']/max(df['element_height'])
  
  df['element_left_relative']<-df['element_left']/max(df['element_width'])
  
  df
}


```

</font>


- x' es la proporcion de x respecto al rango total (ancho del canvas)

<font size = 3>
_mi nueva variable x' es: la linea roja dividida la linea azul_
</font>


```{r, out.width= "65%", out.extra='style="float:left; padding:20px"', echo = F}
knitr::include_graphics("/img/x_demo_plot.jpeg")
```



- y' es la proporcion de y respecto al rango total (alto del canvas)

<font size = 3>
_mi nueva variable y' es: la linea roja dividida la linea azul_
</font>




```{r, out.width= "65%", out.extra='style="float:left; padding:20px"', echo = F}
knitr::include_graphics("/img/demo_plot_y.jpeg")
```




- areaRelativa es la proporcion del area del elemento respecto al total

<font size = 3>
_mi nueva variable areaRelativa es: el area del cuadrado chiquito dividido la del rectangulo grande_
</font>


```{r, out.width= "65%", out.extra='style="float:left; padding:20px"', echo = F}
knitr::include_graphics("/img/area_plot.jpeg")
```



- disposicion (dividiendo alto por acho) es para saber si el elemento es horizontal, vertical, o cuadrado

<font size = 3>
_mi nueva variable disposicion es: el alto dividido por el ancho_
</font>

```{r,out.width= "30%", out.extra='style="float:center; padding:0% 35%"',echo=F}
knitr::include_graphics("/img/rectangular.png")

```



## Resultados

Para empezar a evaluar los resultados, todo "spread" tiene que tener su "gather":

```{r, eval=F, echo=T, size='tiny'} 

gather_file<-function(gdf){
  x<-strsplit(colnames(gdf), '\\.')
  
  element_name=unique(unlist(map(x, 1)))
  original_cols=unique(unlist(map(x, 2)))
  gdf1<-data.frame(element_name)
  gdf1[original_cols[1]]<-0
  gdf1[original_cols[2]]<-0
  gdf1[original_cols[3]]<-0
  gdf1[original_cols[4]]<-0
  
  
  
  rel_area<-c()
  orientation<-c()
  element_top_relative<-c()
  element_left_relative<-c()
  
  for(i in seq(from=1, to=length(gdf), by=4)){
    #  stuff, such as
    rel_area=c(rel_area,gdf[i])
    orientation=c(orientation,gdf[i+1])
    element_top_relative = c(element_top_relative,gdf[i+2])
    element_left_relative = c(element_left_relative,gdf[i+3])
  }
  
  gdf1['rel_area']=as_vector(unlist(rel_area))
  gdf1['orientation']=as_vector(unlist(orientation))
  gdf1['element_top_relative']=as_vector(unlist(element_top_relative))
  gdf1['element_left_relative']=as_vector(unlist(element_left_relative))
  gdf1}


```

En principio veamos como quedaron los grupos sin normalizar y con la normalización


```{r,out.width= "30%", out.extra='style="float:center; padding:0% 35%"', echo = F}
knitr::include_graphics("/img/unnamed-chunk-12-1.png")

```

Y finalmente, un par de ejemplos por grupo:


Primer cluster:

```{r,out.width= "30%", out.extra='style="float:center; padding:0% 35%"', echo = F}
knitr::include_graphics("/img/c1img.jpeg")

```
000003.png

Segundo cluster:

```{r,out.width= "30%", out.extra='style="float:center; padding:0% 35%"', echo = F}
knitr::include_graphics("/img/cl2img.jpeg")

```


Tercero:


```{r,out.width= "30%", out.extra='style="float:center; padding:0% 35%"', echo = F}
knitr::include_graphics("/img/cl3img.jpeg")

```
